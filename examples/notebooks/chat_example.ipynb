{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"/teamspace/studios/this_studio/beta/.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta import Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import json\n",
    "\n",
    "\n",
    "def on_file_selected(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        file_content = change['new']\n",
    "        if not file_content:\n",
    "            print(\"No file selected\")\n",
    "            return\n",
    "        \n",
    "        print(\"File content type:\", type(file_content))\n",
    "        print(\"File content:\", file_content)\n",
    "        \n",
    "        # Handle the tuple structure\n",
    "        if isinstance(file_content, tuple) and len(file_content) > 0:\n",
    "            file_data = file_content[0]\n",
    "            file_name = file_data['name']\n",
    "            \n",
    "            print(f\"Selected file: {file_name}\")\n",
    "            print(\"File data type:\", type(file_data))\n",
    "            \n",
    "            try:\n",
    "                # Create the Artifact\n",
    "                artifact = Artifact(files=[file_name])\n",
    "                print(\"Artifact created successfully\")\n",
    "                print(\"Artifact DataFrame:\")\n",
    "                artifact.df.collect().show()\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating Artifact: {str(e)}\")\n",
    "        else:\n",
    "            print(\"Unexpected file content format\")\n",
    "\n",
    "# Create a file upload widget\n",
    "file_upload = widgets.FileUpload(\n",
    "    accept='',  # Accept all file types\n",
    "    multiple=False  # Allow only single file selection\n",
    ")\n",
    "\n",
    "# Display the file upload widget\n",
    "display(file_upload)\n",
    "\n",
    "# Attach the callback to the file upload widget\n",
    "file_upload.observe(on_file_selected, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    }
   ],
   "source": [
    "papers = Artifact(files=[\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2401.05459v2.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2401.18059.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2402.01680v2.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2402.01968v1.pdf\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: PyMicroPartition::to_table, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: PyMicroPartition::to_table, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table class=\"dataframe\">\n",
       "<thead><tr><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">artifact_uri<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">checksum<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">created_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">extension<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">id<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">inserted_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">mime_type<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">name<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">payload<br />Binary</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">size_bytes<br />Int64</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">type<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">updated_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">version<br />Utf8</th></tr></thead>\n",
       "<tbody>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\"></div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">9446b09e3c50abf6b0bc1fcec3f97e09</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T16:41:19.589546</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J884YDF5W3ZRF8KZ9X90KN7M</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T16:41:19.589546</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2401.05459v2.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xaf\\xa5\\xedf\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">4276555</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T16:41:19.589546</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\"></div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">bef90ad5efc208f8c214dec982b3f4a1</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T16:41:19.812750</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J884YDP4M1YQXQQA9M4RZFM7</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T16:41:19.812750</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2401.18059.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xaf\\xa5\\xedf\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2547113</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T16:41:19.812750</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\"></div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">6ebd968a706c836ef2a9062d59c6bb7c</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T16:41:19.897665</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J884YDRSYMCEVD7CEQ9GA264</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T16:41:19.897665</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2402.01680v2.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xaf\\xa5\\xedf\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1243493</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T16:41:19.897665</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\"></div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">f4e5524a0215616816ec4716c6bf709f</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T16:41:19.944882</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J884YDT87DQXB6YS96VHVQW0</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T16:41:19.944882</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2402.01968v1.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xaf\\xa5\\xedf\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">418187</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T16:41:19.944882</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<small>(Showing first 4 of 4 rows)</small>\n",
       "</div>"
      ],
      "text/plain": [
       "╭──────────────┬────────────────────────┬────────────────────────┬────────────┬──────┬───────────────────────┬─────────╮\n",
       "│ artifact_uri ┆ checksum               ┆ created_at             ┆      …     ┆ type ┆ updated_at            ┆ version │\n",
       "│ ---          ┆ ---                    ┆ ---                    ┆            ┆ ---  ┆ ---                   ┆ ---     │\n",
       "│ Utf8         ┆ Utf8                   ┆ Utf8                   ┆ (7 hidden) ┆ Utf8 ┆ Utf8                  ┆ Utf8    │\n",
       "╞══════════════╪════════════════════════╪════════════════════════╪════════════╪══════╪═══════════════════════╪═════════╡\n",
       "│              ┆ 9446b09e3c50abf6b0bc1f ┆ 2024-09-20T16:41:19.58 ┆ …          ┆ file ┆ 2024-09-20T16:41:19.5 ┆ 1.0     │\n",
       "│              ┆ cec3f97…               ┆ 9546                   ┆            ┆      ┆ 89546                 ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│              ┆ bef90ad5efc208f8c214de ┆ 2024-09-20T16:41:19.81 ┆ …          ┆ file ┆ 2024-09-20T16:41:19.8 ┆ 1.0     │\n",
       "│              ┆ c982b3f…               ┆ 2750                   ┆            ┆      ┆ 12750                 ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│              ┆ 6ebd968a706c836ef2a906 ┆ 2024-09-20T16:41:19.89 ┆ …          ┆ file ┆ 2024-09-20T16:41:19.8 ┆ 1.0     │\n",
       "│              ┆ 2d59c6b…               ┆ 7665                   ┆            ┆      ┆ 97665                 ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│              ┆ f4e5524a0215616816ec47 ┆ 2024-09-20T16:41:19.94 ┆ …          ┆ file ┆ 2024-09-20T16:41:19.9 ┆ 1.0     │\n",
       "│              ┆ 16c6bf7…               ┆ 4882                   ┆            ┆      ┆ 44882                 ┆         │\n",
       "╰──────────────┴────────────────────────┴────────────────────────┴────────────┴──────┴───────────────────────┴─────────╯\n",
       "\n",
       "(Showing first 4 of 4 rows)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.agents import Agent\n",
    "from beta.models.obj.model_object import VLLM\n",
    "from vllm import LLM\n",
    "from beta.tools.obj import CalculatorTool, DataFrameTool\n",
    "from beta.models.serve.engines import VLLMEngine\n",
    "from beta.models.serve.engines import OpenAIEngineConfig\n",
    "from mlflow.client import MlflowClient\n",
    "from daft import DataFrame\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"Dratos AI\")\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model\", \"gpt-4o\")\n",
    "    mlflow.log_param(\"temperature\", 0.5)\n",
    "    mlflow.log_param(\"max_tokens\", 4096)\n",
    "    mlflow.log_param(\"top_p\", 1)\n",
    "    mlflow.log_param(\"frequency_penalty\", 0)\n",
    "    mlflow.log_param(\"presence_penalty\", 0)\n",
    "    prompt = \"What is the capital of Africa?\"\n",
    "    mlflow.log_param(\"prompt\", prompt)\n",
    "\n",
    "    config = OpenAIEngineConfig(data={\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"top_p\": 1,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    })\n",
    "    engine = OpenAIEngine(model_name=\"gpt-4o\", config=config)\n",
    "    response = await engine.generate_structured(prompt, structure=\"{city: str, capital: str}\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.prompts import prompt\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"{{ question }}\"\"\"\n",
    "\n",
    "@prompt\n",
    "def cot(my_prompt, max_steps):\n",
    "    \"\"\"\n",
    "    System: \n",
    "        Using Chain of Thought:\n",
    "        max_steps = {{max_steps}}\n",
    "\n",
    "        for step in max_steps:\n",
    "            Reason about the request and append, \"Therefore\"\n",
    "        \n",
    "        Make a concluding response \n",
    "\n",
    "    User:\n",
    "    {{ my_prompt }}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from datetime import date\n",
    "from ray import serve\n",
    "@serve.deployment(name=\"Test0\")\n",
    "class QuarterlyEarnings(BaseModel):\n",
    "    company_name: str = Field(..., description=\"Name of the company\")\n",
    "    fiscal_quarter: int = Field(..., ge=1, le=4, description=\"Fiscal quarter (1-4)\")\n",
    "    fiscal_year: int = Field(..., description=\"Fiscal year\")\n",
    "    revenue: float = Field(..., description=\"Total revenue for the quarter\")\n",
    "    net_income: float = Field(..., description=\"Net income for the quarter\")\n",
    "    earnings_per_share: float = Field(..., description=\"Earnings per share\")\n",
    "    report_date: date = Field(..., description=\"Date of the earnings report\")\n",
    "    analyst_expectations_met: Optional[bool] = Field(None, description=\"Whether analyst expectations were met\")\n",
    "    key_highlights: Optional[List[str]] = Field(None, description=\"Key highlights from the earnings report\")\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return \"QuarterlyEarnings deployment is working\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine\n",
    "\n",
    "def openai_engine_serializer(engine):\n",
    "    # Return the arguments needed to reconstruct the engine\n",
    "    return (engine.model_name, engine.config)\n",
    "\n",
    "def openai_engine_deserializer(model_name, config):\n",
    "    # Reconstruct the engine\n",
    "    return OpenAIEngine(model_name=model_name, config=config)\n",
    "\n",
    "# Register the custom serializer with Ray\n",
    "ray.util.register_serializer(\n",
    "    OpenAIEngine,\n",
    "    serializer=openai_engine_serializer,\n",
    "    deserializer=openai_engine_deserializer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import inspect\n",
    "from pydantic import BaseModel\n",
    "import daft\n",
    "from ray import serve\n",
    "from typing import get_origin, get_args\n",
    "\n",
    "def pydantic_to_daft_schema(model_class):\n",
    "    if isinstance(model_class, serve.Deployment):\n",
    "        # This is a Ray Serve deployment\n",
    "        model_class = model_class.func_or_class\n",
    "\n",
    "    if not inspect.isclass(model_class) or not issubclass(model_class, BaseModel):\n",
    "        raise ValueError(\"Input must be a Pydantic model class or a Ray Serve deployment of a Pydantic model\")\n",
    "\n",
    "    field_dict = {}\n",
    "    for name, field in model_class.model_fields.items():\n",
    "        if field.annotation == str:\n",
    "            field_dict[name] = daft.DataType.string()\n",
    "        elif field.annotation == int:\n",
    "            field_dict[name] = daft.DataType.int64()\n",
    "        elif field.annotation == float:\n",
    "            field_dict[name] = daft.DataType.float64()\n",
    "        elif field.annotation == bool:\n",
    "            field_dict[name] = daft.DataType.boolean()\n",
    "        elif field.annotation == datetime.date:\n",
    "            field_dict[name] = daft.DataType.date()\n",
    "        elif get_origin(field.annotation) == list and get_args(field.annotation)[0] == str:\n",
    "            field_dict[name] = daft.DataType.list(daft.DataType.string())\n",
    "        else:\n",
    "            field_dict[name] = daft.DataType.python()  # Fallback for complex types\n",
    "    return daft.DataType.struct(field_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Cell: Generate Sample Revenue DataFrames\n",
    "\n",
    "from datetime import date\n",
    "from pydantic import BaseModel\n",
    "import daft\n",
    "\n",
    "# Define sample data for Q4 2024\n",
    "sample_data = [\n",
    "    {\n",
    "        \"company_name\": \"ABC Corp\",\n",
    "        \"fiscal_quarter\": 4,\n",
    "        \"fiscal_year\": 2024,\n",
    "        \"revenue\": 500000.0,\n",
    "        \"net_income\": 120000.0,\n",
    "        \"earnings_per_share\": 2.5,\n",
    "        \"report_date\": date(2024, 10, 31),\n",
    "        \"analyst_expectations_met\": True,\n",
    "        \"key_highlights\": [\n",
    "            \"Increased sales in electronics\",\n",
    "            \"Expanded to new markets\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"ABC Corp\",\n",
    "        \"fiscal_quarter\": 4,\n",
    "        \"fiscal_year\": 2024,\n",
    "        \"revenue\": 600000.0,\n",
    "        \"net_income\": 150000.0,\n",
    "        \"earnings_per_share\": 3.0,\n",
    "        \"report_date\": date(2024, 11, 30),\n",
    "        \"analyst_expectations_met\": False,\n",
    "        \"key_highlights\": [\n",
    "            \"Supply chain disruptions\",\n",
    "            \"Higher marketing expenses\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"ABC Corp\",\n",
    "        \"fiscal_quarter\": 4,\n",
    "        \"fiscal_year\": 2024,\n",
    "        \"revenue\": 550000.0,\n",
    "        \"net_income\": 130000.0,\n",
    "        \"earnings_per_share\": 2.8,\n",
    "        \"report_date\": date(2024, 12, 31),\n",
    "        \"analyst_expectations_met\": True,\n",
    "        \"key_highlights\": [\n",
    "            \"Improved operational efficiencies\",\n",
    "            \"New product launch success\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert sample data to QuarterlyEarnings instances\n",
    "quarterly_earnings_instances = [QuarterlyEarnings(**item) for item in sample_data]\n",
    "\n",
    "# Create a Daft DataFrame from Pydantic models\n",
    "revenue_df = daft.from_pydantic(QuarterlyEarnings, quarterly_earnings_instances)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Sample Revenue DataFrame:\")\n",
    "revenue_df.collect().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from daft import Schema\n",
    "import daft\n",
    "import json\n",
    "import ray\n",
    "from ray import serve\n",
    "from beta.agents.agent import Agent, Metadata, SchemaWrapper\n",
    "from beta.tools.obj.calculator_tool import CalculatorTool\n",
    "from beta.tools.obj.dataframe_tool import DataFrameTool\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine, OpenAIEngineConfig\n",
    "\n",
    "# Initialize Ray and Serve\n",
    "ray.init(ignore_reinit_error=True)\n",
    "serve.start()\n",
    "\n",
    "# Create OpenAIEngine instances\n",
    "config = OpenAIEngineConfig(data={\n",
    "    \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    \"temperature\": 0.5,\n",
    "    \"max_tokens\": 4096,\n",
    "    \"top_p\": 1,\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"presence_penalty\": 0\n",
    "})  \n",
    "model_engine = OpenAIEngine(model_name=\"gpt-4o\", config=config)\n",
    "embedding_engine = OpenAIEngine(model_name=\"gpt-4o\", config=config)\n",
    "stt_engine = OpenAIEngine(model_name=\"gpt-4o\", config=config)\n",
    "\n",
    "# QuarterlyEarnings as a DataFrame Schema\n",
    "QuarterlyEarningsSchema = pydantic_to_daft_schema(QuarterlyEarnings)\n",
    "\n",
    "# Create the Agent\n",
    "q1_agent = Agent(\n",
    "    name=\"Q1 Agent\",\n",
    "    model=model_engine,\n",
    "    embedding=embedding_engine,\n",
    "    stt=stt_engine,\n",
    "    tools=[CalculatorTool, DataFrameTool],\n",
    "    metadata=Metadata(schema=SchemaWrapper(schema=QuarterlyEarningsSchema)),\n",
    "    engine=model_engine,\n",
    "    memory=[earnings],\n",
    "    is_async=True\n",
    ")\n",
    "\n",
    "from beta.prompts import prompt\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"What were the key highlights of the Q4 2024 earnings?\"\"\"\n",
    "\n",
    "response = await q1_agent.process(prompt=my_prompt())\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Cell: Using CalculatorTool and DataFrameTool with Agent\n",
    "\n",
    "from beta.tools import CalculatorTool, DataFrameTool\n",
    "from beta.agents import Agent\n",
    "from beta.prompts import prompt\n",
    "\n",
    "# Define a new prompt that leverages both tools\n",
    "@prompt\n",
    "def compute_and_analyze(question):\n",
    "    \"\"\"\n",
    "    You are an intelligent assistant equipped with Calculator and DataFrame tools.\n",
    "    \n",
    "    Task:\n",
    "    - Calculate the total revenue for Q4 2024.\n",
    "    - Provide a summary of key highlights in a table format.\n",
    "    \n",
    "    User Question:\n",
    "    {{ question }}\n",
    "    \"\"\"\n",
    "\n",
    "# Initialize the Agent with CalculatorTool and DataFrameTool\n",
    "compute_analyze_agent = Agent(\n",
    "    name=\"ComputeAnalyzeAgent\",\n",
    "    model=model_engine,          # Ensure model_engine is defined in your environment\n",
    "    embedding=embedding_engine,  # Ensure embedding_engine is defined in your environment\n",
    "    stt=stt_engine,              # Ensure stt_engine is defined in your environment\n",
    "    tools=[CalculatorTool, DataFrameTool],\n",
    "    metadata=Metadata(schema=SchemaWrapper(schema=QuarterlyEarningsSchema)),\n",
    "    engine=model_engine,\n",
    "    is_async=True\n",
    ")\n",
    "\n",
    "# Define the question to be processed\n",
    "question = \"Calculate the total revenue for Q4 2024 and provide a summary of key highlights in a table.\"\n",
    "\n",
    "# Debugging: Print the constructed prompt before processing\n",
    "constructed_prompt = compute_and_analyze(question)\n",
    "print(\"Constructed Prompt:\")\n",
    "print(constructed_prompt)\n",
    "\n",
    "# Process the prompt with the agent\n",
    "response = await compute_analyze_agent.process(prompt=constructed_prompt)\n",
    "\n",
    "# Display the response\n",
    "print(\"Agent Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from returns.future import Future\n",
    "\n",
    "async def process_agent_response(prompt):\n",
    "    return Future.from_sync(lambda: q1_agent.process(my_prompt(prompt)))\n",
    "\n",
    "response = await process_agent_response(\"What were the key highlights of the Q4 2024 earnings?\").close()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client = MlflowClient(\"http://localhost:5000\")\n",
    "config = OpenAIEngineConfig(data={\"temperature\": 0.5, \"max_tokens\": 4096, \"top_p\": 1, \"frequency_penalty\": 0, \"presence_penalty\": 0})\n",
    "llm = LLM(model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "vllm = VLLM(model=LLM)\n",
    "engine = VLLMEngine(model_name=\"meta-llama/Meta-Llama-3.1-8B-Instruct\", mlflow_client=mlflow_client, config=config, api_key=\"EMPTY\", base_url=\"http://localhost:8000\")\n",
    "\n",
    "paligemma = vllm(\n",
    "    model_name=\"google/paligemma-3b-mix-448\",\n",
    "    engine=engine,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.models.obj import llm\n",
    "from beta.models.serve.engines import LitServeEngine, OpenAIEngine, OpenRouterEngine, VLLMEngine\n",
    "\n",
    "\n",
    "completion_settings = llm.settings(\n",
    "    temperature=0.5,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    ")\n",
    "\n",
    "# Defaults to OpenRouter\n",
    "# Expects OPENROUTER_API_KEY to be defined in .env\n",
    "gemini_free = llm(\n",
    "    model_name=\"google/gemini-pro-1.5-flash\",\n",
    "    settings=completion_settings,\n",
    ")\n",
    "\n",
    "# If OPENAI_API_KEY, uses { OpenAi | AsyncOpenAI } clients instead of OpenRouter. \n",
    "gpt4o = llm(\n",
    "    model_name=\"openai/o1-mini\",\n",
    "    settings=completion_settings,\n",
    ")\n",
    "\n",
    "# If ANTHROPIC_API_KEY, uses {Anthropic | AsyncAnthopic }\n",
    "sonnet = llm(\n",
    "    model_name=\"anthopic/claude-3.5-sonnet\",\n",
    "    settings = completion_settings,\n",
    ")\n",
    "\n",
    "\n",
    "# Specifying the Engine with OS Model\n",
    "paligemma = llm(\n",
    "    model_name=\"google/paligemma-3b-mix-448\",\n",
    "    engine=LitServeEngine(), \n",
    "    completion_settings=completion_settings\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.tools import CalculatorTool, DataframeTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from beta.agents import BaseAgent, SpeechAgent\n",
    "\n",
    "artifact_df = daft.DataFrame()\n",
    "node_df = daft.DataFrame()\n",
    "document_df = daft.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "earnings = Data.Projects.get(\"Earnings Q4 2024\")\n",
    "knowledge_graph = my_project.Graphs.get(\"latest\")\n",
    "\n",
    "\n",
    "q1_agent = Agent(\n",
    "    llm=paligemma,\n",
    "    tools=[CalculatorTool, DataframeTool],\n",
    "    context=[earnings],\n",
    "    memory={'short':[knowl]},\n",
    "    planning=\n",
    "    rethinking=\n",
    ")\n",
    "\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"{{ question}}\"\"\"\n",
    "\n",
    "@prompt\n",
    "def cot(my_prompt,max_steps):\n",
    "    \"\"\"\n",
    "    System: \n",
    "        Using Chain of Thought:\n",
    "        max_steps = {{max_steps}}\n",
    "\n",
    "        for step in max_steps:\n",
    "            Reason about the request and append, \"Therefore\"\n",
    "        \n",
    "        Make a concluding response \n",
    "\n",
    "    User:\n",
    "    {{ my_prompt }}\n",
    "    \"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from datetime import date\n",
    "\n",
    "class QuarterlyEarnings(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents quarterly earnings data for a company.\n",
    "    \"\"\"\n",
    "    company_name: str = Field(..., description=\"Name of the company\")\n",
    "    fiscal_quarter: int = Field(..., ge=1, le=4, description=\"Fiscal quarter (1-4)\")\n",
    "    fiscal_year: int = Field(..., description=\"Fiscal year\")\n",
    "    revenue: float = Field(..., description=\"Total revenue for the quarter\")\n",
    "    net_income: float = Field(..., description=\"Net income for the quarter\")\n",
    "    earnings_per_share: float = Field(..., description=\"Earnings per share\")\n",
    "    report_date: date = Field(..., description=\"Date of the earnings report\")\n",
    "    analyst_expectations_met: Optional[bool] = Field(None, description=\"Whether analyst expectations were met\")\n",
    "    key_highlights: Optional[List[str]] = Field(None, description=\"Key highlights from the earnings report\")\n",
    "\n",
    "\n",
    "response = await my_agent(\n",
    "    prompt=\n",
    "    response_model=[Address], \n",
    "        reponse_model_strict = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
