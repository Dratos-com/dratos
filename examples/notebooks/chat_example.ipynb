{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"/teamspace/studios/this_studio/beta/.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"schema\" in \"SchemaWrapper\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"schema\" in \"Metadata\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    }
   ],
   "source": [
    "from beta import Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f9b1b32b4e46d0aa189a9781d4f0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import json\n",
    "\n",
    "\n",
    "def on_file_selected(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        file_content = change['new']\n",
    "        if not file_content:\n",
    "            print(\"No file selected\")\n",
    "            return\n",
    "        \n",
    "        print(\"File content type:\", type(file_content))\n",
    "        print(\"File content:\", file_content)\n",
    "        \n",
    "        # Handle the tuple structure\n",
    "        if isinstance(file_content, tuple) and len(file_content) > 0:\n",
    "            file_data = file_content[0]\n",
    "            file_name = file_data['name']\n",
    "            \n",
    "            print(f\"Selected file: {file_name}\")\n",
    "            print(\"File data type:\", type(file_data))\n",
    "            \n",
    "            try:\n",
    "                # Create the Artifact\n",
    "                artifact = Artifact(files=[file_name])\n",
    "                print(\"Artifact created successfully\")\n",
    "                print(\"Artifact DataFrame:\")\n",
    "                artifact.df.collect().show()\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating Artifact: {str(e)}\")\n",
    "        else:\n",
    "            print(\"Unexpected file content format\")\n",
    "\n",
    "# Create a file upload widget\n",
    "file_upload = widgets.FileUpload(\n",
    "    accept='',  # Accept all file types\n",
    "    multiple=False  # Allow only single file selection\n",
    ")\n",
    "\n",
    "# Display the file upload widget\n",
    "display(file_upload)\n",
    "\n",
    "# Attach the callback to the file upload widget\n",
    "file_upload.observe(on_file_selected, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-21\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.date(datetime.now())\n",
    "print(str(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    }
   ],
   "source": [
    "artifact_repository = f\"/teamspace/uploads/artifacts/payloads/{str(today)}/\"\n",
    "\n",
    "papers = Artifact(files=[\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2401.05459v2.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2401.18059.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2402.01680v2.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2402.01968v1.pdf\"\n",
    "], uri_prefix=artifact_repository)\n",
    "\n",
    "br_23_earnings = Artifact(files=[\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 1Q23 Earnings Release.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 2Q23 Earnings Release.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 3Q23 Earnings Release.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 4Q23 Earnings Release.pdf\"\n",
    "], uri_prefix=artifact_repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: PyMicroPartition::to_table, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: PyMicroPartition::to_table, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table class=\"dataframe\">\n",
       "<thead><tr><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">artifact_uri<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">checksum<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">created_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">extension<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">id<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">inserted_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">mime_type<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">name<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">payload<br />Binary</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">size_bytes<br />Int64</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">type<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">updated_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">version<br />Utf8</th></tr></thead>\n",
       "<tbody>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-21//01J8ABGJJJFCZ8FNVZ85XA6QDE__BLK 1Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">91f1ec0a9dbc64375b730641fd248101</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:14:34.962535</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J8ABGJJJFCZ8FNVZ85XA6QDE</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:14:34.962535</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 1Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xba\\xc6\\xeef\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1061830</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:14:34.962535</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-21//01J8ABGJKN8SQ4X1S06G7CNPM3__BLK 2Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">413cb79dd3084d282a821f61d53c401c</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:14:34.997278</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J8ABGJKN8SQ4X1S06G7CNPM3</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:14:34.997278</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 2Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xba\\xc6\\xeef\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">316186</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:14:34.997278</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-21//01J8ABGJKXD9RRGWR31M482FDE__BLK 3Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">aea5a59de7f6ebdd8145891af2a0f16c</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:14:35.005177</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J8ABGJKXD9RRGWR31M482FDE</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:14:35.005177</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 3Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xbb\\xc6\\xeef\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">321016</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:14:35.005177</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-21//01J8ABGJM5JFSH1K9C5PT8FGEY__BLK 4Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">3d6086d1eb1aac9e82b80b86913b751a</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:14:35.013195</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J8ABGJM5JFSH1K9C5PT8FGEY</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:14:35.013195</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 4Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xbb\\xc6\\xeef\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">316432</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:14:35.013195</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<small>(Showing first 4 of 4 rows)</small>\n",
       "</div>"
      ],
      "text/plain": [
       "╭──────────────────────┬─────────────────────┬─────────────────────┬────────────┬──────┬─────────────────────┬─────────╮\n",
       "│ artifact_uri         ┆ checksum            ┆ created_at          ┆      …     ┆ type ┆ updated_at          ┆ version │\n",
       "│ ---                  ┆ ---                 ┆ ---                 ┆            ┆ ---  ┆ ---                 ┆ ---     │\n",
       "│ Utf8                 ┆ Utf8                ┆ Utf8                ┆ (7 hidden) ┆ Utf8 ┆ Utf8                ┆ Utf8    │\n",
       "╞══════════════════════╪═════════════════════╪═════════════════════╪════════════╪══════╪═════════════════════╪═════════╡\n",
       "│ /teamspace/uploads/a ┆ 91f1ec0a9dbc64375b7 ┆ 2024-09-21T13:14:34 ┆ …          ┆ file ┆ 2024-09-21T13:14:34 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 30641fd248…         ┆ .962535             ┆            ┆      ┆ .962535             ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ /teamspace/uploads/a ┆ 413cb79dd3084d282a8 ┆ 2024-09-21T13:14:34 ┆ …          ┆ file ┆ 2024-09-21T13:14:34 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 21f61d53c4…         ┆ .997278             ┆            ┆      ┆ .997278             ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ /teamspace/uploads/a ┆ aea5a59de7f6ebdd814 ┆ 2024-09-21T13:14:35 ┆ …          ┆ file ┆ 2024-09-21T13:14:35 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 5891af2a0f…         ┆ .005177             ┆            ┆      ┆ .005177             ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ /teamspace/uploads/a ┆ 3d6086d1eb1aac9e82b ┆ 2024-09-21T13:14:35 ┆ …          ┆ file ┆ 2024-09-21T13:14:35 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 80b86913b7…         ┆ .013195             ┆            ┆      ┆ .013195             ┆         │\n",
       "╰──────────────────────┴─────────────────────┴─────────────────────┴────────────┴──────┴─────────────────────┴─────────╯\n",
       "\n",
       "(Showing first 4 of 4 rows)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.df.collect()\n",
    "br_23_earnings.df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Artifact Persistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta import Agent\n",
    "from vllm import LLM\n",
    "from beta.tools.obj import CalculatorTool, DataFrameTool\n",
    "from beta.models.serve.engines import VLLMEngine\n",
    "from beta.models.serve.engines import OpenAIEngineConfig\n",
    "from mlflow.client import MlflowClient\n",
    "from daft import DataFrame\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/models \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"city\": \"Africa is a continent and does not have a capital\",\n",
      "  \"capital\": \"Africa is a continent and does not have a capital\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine, OpenAIEngineConfig\n",
    "mlflow.set_experiment(\"Dratos AI\")\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model\", \"gpt-4o\")\n",
    "    mlflow.log_param(\"temperature\", 0.5)\n",
    "    mlflow.log_param(\"max_tokens\", 4096)\n",
    "    mlflow.log_param(\"top_p\", 1)\n",
    "    mlflow.log_param(\"frequency_penalty\", 0)\n",
    "    mlflow.log_param(\"presence_penalty\", 0)\n",
    "    prompt = \"What is the capital of Africa?\"\n",
    "    mlflow.log_param(\"prompt\", prompt)\n",
    "\n",
    "    config = OpenAIEngineConfig(data={\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"top_p\": 1,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    })\n",
    "    engine = OpenAIEngine(config=config)\n",
    "    response = await engine.generate_structured(prompt, structure=\"{city: str, capital: str}\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.prompts import prompt\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"{{ question }}\"\"\"\n",
    "\n",
    "@prompt\n",
    "def cot(my_prompt, max_steps):\n",
    "    \"\"\"\n",
    "    System: \n",
    "        Using Chain of Thought:\n",
    "        max_steps = {{max_steps}}\n",
    "\n",
    "        for step in max_steps:\n",
    "            Reason about the request and append, \"Therefore\"\n",
    "        \n",
    "        Make a concluding response \n",
    "\n",
    "    User:\n",
    "    {{ my_prompt }}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from datetime import date\n",
    "from ray import serve\n",
    "\n",
    "@serve.deployment(name=\"QuarterlyEarningsDeployment\")\n",
    "class QuarterlyEarningsDeployment(BaseModel):\n",
    "    company_name: str = Field(..., description=\"Name of the company\")\n",
    "    fiscal_quarter: int = Field(..., ge=1, le=4, description=\"Fiscal quarter (1-4)\")\n",
    "    fiscal_year: int = Field(..., description=\"Fiscal year\")\n",
    "    revenue: float = Field(..., description=\"Total revenue for the quarter\")\n",
    "    net_income: float = Field(..., description=\"Net income for the quarter\")\n",
    "    earnings_per_share: float = Field(..., description=\"Earnings per share\")\n",
    "    report_date: date = Field(..., description=\"Date of the earnings report\")\n",
    "    analyst_expectations_met: Optional[bool] = Field(None, description=\"Whether analyst expectations were met\")\n",
    "    key_highlights: Optional[List[str]] = Field(None, description=\"Key highlights from the earnings report\")\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return \"QuarterlyEarnings deployment is working\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine\n",
    "\n",
    "def openai_engine_serializer(engine):\n",
    "    # Return the arguments needed to reconstruct the engine\n",
    "    return (engine.model_name, engine.config)\n",
    "\n",
    "def openai_engine_deserializer(model_name, config):\n",
    "    # Reconstruct the engine\n",
    "    return OpenAIEngine(model_name=model_name, config=config)\n",
    "\n",
    "# Register the custom serializer with Ray\n",
    "ray.util.register_serializer(\n",
    "    OpenAIEngine,\n",
    "    serializer=openai_engine_serializer,\n",
    "    deserializer=openai_engine_deserializer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import inspect\n",
    "from pydantic import BaseModel\n",
    "import daft\n",
    "from ray import serve\n",
    "from typing import get_origin, get_args\n",
    "\n",
    "def pydantic_to_daft_schema(model_class):\n",
    "    if isinstance(model_class, serve.Deployment):\n",
    "        # This is a Ray Serve deployment\n",
    "        model_class = model_class.func_or_class\n",
    "\n",
    "    if not inspect.isclass(model_class) or not issubclass(model_class, BaseModel):\n",
    "        raise ValueError(\"Input must be a Pydantic model class or a Ray Serve deployment of a Pydantic model\")\n",
    "\n",
    "    field_dict = {}\n",
    "    for name, field in model_class.model_fields.items():\n",
    "        if field.annotation == str:\n",
    "            field_dict[name] = daft.DataType.string()\n",
    "        elif field.annotation == int:\n",
    "            field_dict[name] = daft.DataType.int64()\n",
    "        elif field.annotation == float:\n",
    "            field_dict[name] = daft.DataType.float64()\n",
    "        elif field.annotation == bool:\n",
    "            field_dict[name] = daft.DataType.boolean()\n",
    "        elif field.annotation == datetime.date:\n",
    "            field_dict[name] = daft.DataType.date()\n",
    "        elif get_origin(field.annotation) == list and get_args(field.annotation)[0] == str:\n",
    "            field_dict[name] = daft.DataType.list(daft.DataType.string())\n",
    "        else:\n",
    "            field_dict[name] = daft.DataType.python()  # Fallback for complex types\n",
    "    return daft.DataType.struct(field_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 13:14:37,908\tINFO worker.py:1601 -- Connecting to existing Ray cluster at address: 10.192.12.246:6380...\n",
      "2024-09-21 13:14:37,915\tINFO worker.py:1786 -- Connected to Ray cluster.\n",
      "INFO 2024-09-21 13:14:37,933 serve 363946 api.py:259 - Connecting to existing Serve app in namespace \"serve\". New http options will not be applied.\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:root:Lancedb client connected: LanceDBConnection(lancedb://localhost:5432/lancedb)\n",
      "INFO:root:Agent Q1 Agent called with prompt: What were the key highlights of the Q4 2024 earnings?\n",
      "INFO:root:Agent status set to processing\n",
      "INFO:root:Sending request to model\n",
      "INFO:root:Prompt: What were the key highlights of the Q4 2024 earnings?\n",
      "INFO:root:Storing artifact in LanceDB: <Artifact with 4 files>\n",
      "INFO:daft.runners.pyrunner:Using python executor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1defc0532d741228baec94402c4b966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Project [Stage:1]:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::eval_expression_list, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "ERROR:root:Failed to store artifact vectors in LanceDB: DaftError::ValueError Python Object is neither array-like or an iterable at index 0. Can not convert to a list. object type: <class 'coroutine'>\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: PyMicroPartition::to_table, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "ERROR:root:Artifact data schema: <bound method DataFrame.schema of ╭──────────────────────┬─────────────────────┬─────────────────────┬────────────┬──────┬─────────────────────┬─────────╮\n",
      "│ artifact_uri         ┆ checksum            ┆ created_at          ┆      …     ┆ type ┆ updated_at          ┆ version │\n",
      "│ ---                  ┆ ---                 ┆ ---                 ┆            ┆ ---  ┆ ---                 ┆ ---     │\n",
      "│ Utf8                 ┆ Utf8                ┆ Utf8                ┆ (7 hidden) ┆ Utf8 ┆ Utf8                ┆ Utf8    │\n",
      "╞══════════════════════╪═════════════════════╪═════════════════════╪════════════╪══════╪═════════════════════╪═════════╡\n",
      "│ /teamspace/uploads/a ┆ 91f1ec0a9dbc64375b7 ┆ 2024-09-21T13:14:34 ┆ …          ┆ file ┆ 2024-09-21T13:14:34 ┆ 1.0     │\n",
      "│ rtifacts/…           ┆ 30641fd248…         ┆ .962535             ┆            ┆      ┆ .962535             ┆         │\n",
      "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
      "│ /teamspace/uploads/a ┆ 413cb79dd3084d282a8 ┆ 2024-09-21T13:14:34 ┆ …          ┆ file ┆ 2024-09-21T13:14:34 ┆ 1.0     │\n",
      "│ rtifacts/…           ┆ 21f61d53c4…         ┆ .997278             ┆            ┆      ┆ .997278             ┆         │\n",
      "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
      "│ /teamspace/uploads/a ┆ aea5a59de7f6ebdd814 ┆ 2024-09-21T13:14:35 ┆ …          ┆ file ┆ 2024-09-21T13:14:35 ┆ 1.0     │\n",
      "│ rtifacts/…           ┆ 5891af2a0f…         ┆ .005177             ┆            ┆      ┆ .005177             ┆         │\n",
      "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
      "│ /teamspace/uploads/a ┆ 3d6086d1eb1aac9e82b ┆ 2024-09-21T13:14:35 ┆ …          ┆ file ┆ 2024-09-21T13:14:35 ┆ 1.0     │\n",
      "│ rtifacts/…           ┆ 80b86913b7…         ┆ .013195             ┆            ┆      ┆ .013195             ┆         │\n",
      "╰──────────────────────┴─────────────────────┴─────────────────────┴────────────┴──────┴─────────────────────┴─────────╯\n",
      "\n",
      "(Showing first 4 of 4 rows)>\n"
     ]
    },
    {
     "ename": "APITypeError",
     "evalue": "DataFrame.sample received wrong input type.\nRequired:\n\tfraction = <<class 'float'>>\nGiven:\n\tfraction = <int>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDaftCoreException\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/beta/beta/agents/agent.py:213\u001b[0m, in \u001b[0;36mAgent.store_in_lancedb\u001b[0;34m(self, artifact)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Convert to PyArrow table\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m \u001b[43martifact_embedded_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Check if the vector table exists\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/api_annotations.py:26\u001b[0m, in \u001b[0;36mDataframePublicAPI.<locals>._wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m timed_method \u001b[38;5;241m=\u001b[39m time_df_method(func)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtimed_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/analytics.py:189\u001b[0m, in \u001b[0;36mtime_df_method.<locals>.tracked_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/dataframe/dataframe.py:2215\u001b[0m, in \u001b[0;36mDataFrame.to_arrow\u001b[0;34m(self, cast_tensors_to_ray_tensor_dtype)\u001b[0m\n\u001b[1;32m   2206\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the current DataFrame to a `pyarrow Table <https://arrow.apache.org/docs/python/generated/pyarrow.Table.html>`__.\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m \u001b[38;5;124;03mIf results have not computed yet, collect will be called.\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2213\u001b[0m \u001b[38;5;124;03m        This call is **blocking** and will execute the DataFrame when called\u001b[39;00m\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2216\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/api_annotations.py:26\u001b[0m, in \u001b[0;36mDataframePublicAPI.<locals>._wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m timed_method \u001b[38;5;241m=\u001b[39m time_df_method(func)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtimed_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/analytics.py:189\u001b[0m, in \u001b[0;36mtime_df_method.<locals>.tracked_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/dataframe/dataframe.py:2060\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self, num_preview_rows)\u001b[0m\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Executes the entire DataFrame and materializes the results\u001b[39;00m\n\u001b[1;32m   2050\u001b[0m \n\u001b[1;32m   2051\u001b[0m \u001b[38;5;124;03m.. NOTE::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m    DataFrame: DataFrame with materialized results.\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_materialize_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/dataframe/dataframe.py:2042\u001b[0m, in \u001b[0;36mDataFrame._materialize_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_cache \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_builder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2043\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/runners/pyrunner.py:143\u001b[0m, in \u001b[0;36mPyRunner.run\u001b[0;34m(self, builder)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, builder: LogicalPlanBuilder) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PartitionCacheEntry:\n\u001b[0;32m--> 143\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     result_pset \u001b[38;5;241m=\u001b[39m LocalPartitionSet()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/runners/pyrunner.py:211\u001b[0m, in \u001b[0;36mPyRunner.run_iter\u001b[0;34m(self, builder, results_buffer_size)\u001b[0m\n\u001b[1;32m    210\u001b[0m results_gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_physical_plan_to_partitions(tasks)\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m results_gen\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/runners/pyrunner.py:309\u001b[0m, in \u001b[0;36mPyRunner._physical_plan_to_partitions\u001b[0;34m(self, plan)\u001b[0m\n\u001b[1;32m    308\u001b[0m done_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inflight_tasks\u001b[38;5;241m.\u001b[39mpop(done_id)\n\u001b[0;32m--> 309\u001b[0m materialized_results \u001b[38;5;241m=\u001b[39m \u001b[43mdone_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m pbar\u001b[38;5;241m.\u001b[39mmark_task_done(done_task)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/runners/pyrunner.py:363\u001b[0m, in \u001b[0;36mPyRunner.build_partitions\u001b[0;34m(instruction_stack, partitions, final_metadata)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instruction \u001b[38;5;129;01min\u001b[39;00m instruction_stack:\n\u001b[0;32m--> 363\u001b[0m     partitions \u001b[38;5;241m=\u001b[39m \u001b[43minstruction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    365\u001b[0m     PyMaterializedResult(part, PartitionMetadata\u001b[38;5;241m.\u001b[39mfrom_table(part)\u001b[38;5;241m.\u001b[39mmerge_with_partial(partial))\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m part, partial \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(partitions, final_metadata)\n\u001b[1;32m    367\u001b[0m ]\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/execution/execution_step.py:510\u001b[0m, in \u001b[0;36mProject.run\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: \u001b[38;5;28mlist\u001b[39m[MicroPartition]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[MicroPartition]:\n\u001b[0;32m--> 510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/execution/execution_step.py:514\u001b[0m, in \u001b[0;36mProject._project\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    513\u001b[0m [\u001b[38;5;28minput\u001b[39m] \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m--> 514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_expression_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprojection\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/table/micropartition.py:176\u001b[0m, in \u001b[0;36mMicroPartition.eval_expression_list\u001b[0;34m(self, exprs)\u001b[0m\n\u001b[1;32m    175\u001b[0m pyexprs \u001b[38;5;241m=\u001b[39m [e\u001b[38;5;241m.\u001b[39m_expr \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m exprs]\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MicroPartition\u001b[38;5;241m.\u001b[39m_from_pymicropartition(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_micropartition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_expression_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyexprs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/udf.py:126\u001b[0m, in \u001b[0;36mPartialUDF.__call__\u001b[0;34m(self, evaluated_expressions)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pylist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpyobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mudf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_series\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _NUMPY_AVAILABLE \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/series.py:197\u001b[0m, in \u001b[0;36mSeries.cast\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcast\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: DataType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Series\u001b[38;5;241m.\u001b[39m_from_pyseries(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_series\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mDaftCoreException\u001b[0m: DaftError::ValueError Python Object is neither array-like or an iterable at index 0. Can not convert to a list. object type: <class 'coroutine'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAPITypeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 62\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@prompt\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmy_prompt\u001b[39m(question):\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"What were the key highlights of the Q4 2024 earnings?\"\"\"\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m q1_agent\u001b[38;5;241m.\u001b[39mprocess(prompt\u001b[38;5;241m=\u001b[39mmy_prompt())\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/beta/beta/agents/agent.py:177\u001b[0m, in \u001b[0;36mAgent.process\u001b[0;34m(self, prompt, messages, speech)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifacts:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m artifact \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifacts:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# store in lancedb\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_in_lancedb(artifact)\n\u001b[1;32m    179\u001b[0m llm_response: DeploymentResponse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(prompt\u001b[38;5;241m=\u001b[39mprompt, messages\u001b[38;5;241m=\u001b[39mmessages)\n\u001b[1;32m    180\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAwaiting model response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/beta/beta/agents/agent.py:228\u001b[0m, in \u001b[0;36mAgent.store_in_lancedb\u001b[0;34m(self, artifact)\u001b[0m\n\u001b[1;32m    226\u001b[0m logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to store artifact vectors in LanceDB: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    227\u001b[0m logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArtifact data schema: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_df\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 228\u001b[0m logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArtifact data sample: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43martifact_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcollect()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/api_annotations.py:24\u001b[0m, in \u001b[0;36mDataframePublicAPI.<locals>._wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mtype_check_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     timed_method \u001b[38;5;241m=\u001b[39m time_df_method(func)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m timed_method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/api_annotations.py:101\u001b[0m, in \u001b[0;36mtype_check_function\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param_kind \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m     96\u001b[0m     inspect\u001b[38;5;241m.\u001b[39mParameter\u001b[38;5;241m.\u001b[39mPOSITIONAL_ONLY,\n\u001b[1;32m     97\u001b[0m     inspect\u001b[38;5;241m.\u001b[39mParameter\u001b[38;5;241m.\u001b[39mPOSITIONAL_OR_KEYWORD,\n\u001b[1;32m     98\u001b[0m     inspect\u001b[38;5;241m.\u001b[39mParameter\u001b[38;5;241m.\u001b[39mKEYWORD_ONLY,\n\u001b[1;32m     99\u001b[0m ):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isinstance_helper(value, param_type):\n\u001b[0;32m--> 101\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m APITypeError(\n\u001b[1;32m    102\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m received wrong input type.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequired:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = <\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = <\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m         )\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m param_kind \u001b[38;5;241m==\u001b[39m inspect\u001b[38;5;241m.\u001b[39mParameter\u001b[38;5;241m.\u001b[39mVAR_POSITIONAL:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(value):\n",
      "\u001b[0;31mAPITypeError\u001b[0m: DataFrame.sample received wrong input type.\nRequired:\n\tfraction = <<class 'float'>>\nGiven:\n\tfraction = <int>"
     ]
    }
   ],
   "source": [
    "from daft import Schema\n",
    "import os\n",
    "import daft\n",
    "import json\n",
    "import ray\n",
    "from ray import serve\n",
    "from beta.agents.agent import Agent, Metadata, SchemaWrapper\n",
    "from beta.tools.obj.calculator_tool import CalculatorTool\n",
    "from beta.tools.obj.dataframe_tool import DataFrameTool\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine, OpenAIEngineConfig\n",
    "\n",
    "# Initialize Ray and Serve\n",
    "if not ray.is_initialized():\n",
    "    ray.init(address=\"127.0.0.1:6380\", ignore_reinit_error=True)\n",
    "serve.start()\n",
    "\n",
    "# Create OpenAIEngine instances\n",
    "config = OpenAIEngineConfig(\n",
    "    data={\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"top_p\": 1,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    }\n",
    ")\n",
    "\n",
    "embedding_config = OpenAIEngineConfig(\n",
    "    data={\n",
    "        \"model\": \"text-embedding-ada-002\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"top_p\": 1,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    }\n",
    ")\n",
    "model_engine = OpenAIEngine(config=config)\n",
    "embedding_engine = OpenAIEngine(config=embedding_config)\n",
    "stt_engine = OpenAIEngine(config=config)\n",
    "\n",
    "# Create the Agent\n",
    "q1_agent = Agent(\n",
    "    name=\"Q1 Agent\",\n",
    "    model=model_engine,\n",
    "    embedding=embedding_engine,\n",
    "    stt=stt_engine,\n",
    "    tools=[CalculatorTool, DataFrameTool],\n",
    "    engine=model_engine,\n",
    "    artifacts=[br_23_earnings],\n",
    "    is_async=True,\n",
    ")\n",
    "\n",
    "from beta.prompts import prompt\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"What were the key highlights of the Q4 2024 earnings?\"\"\"\n",
    "\n",
    "response = await q1_agent.process(prompt=my_prompt())\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Cell: Using CalculatorTool and DataFrameTool with Agent\n",
    "\n",
    "from beta.tools import CalculatorTool, DataFrameTool\n",
    "from beta.agents import Agent\n",
    "from beta.prompts import prompt\n",
    "\n",
    "# Define a new prompt that leverages both tools\n",
    "@prompt\n",
    "def compute_and_analyze(question):\n",
    "    \"\"\"\n",
    "    You are an intelligent assistant equipped with Calculator and DataFrame tools.\n",
    "    \n",
    "    Task:\n",
    "    - Calculate the total revenue for Q4 2024.\n",
    "    - Provide a summary of key highlights in a table format.\n",
    "    \n",
    "    User Question:\n",
    "    {{ question }}\n",
    "    \"\"\"\n",
    "\n",
    "# Initialize the Agent with CalculatorTool and DataFrameTool\n",
    "compute_analyze_agent = Agent(\n",
    "    name=\"ComputeAnalyzeAgent\",\n",
    "    model=model_engine,          # Ensure model_engine is defined in your environment\n",
    "    embedding=embedding_engine,  # Ensure embedding_engine is defined in your environment\n",
    "    stt=stt_engine,              # Ensure stt_engine is defined in your environment\n",
    "    tools=[CalculatorTool, DataFrameTool],\n",
    "    metadata=Metadata(schema=SchemaWrapper(schema=QuarterlyEarningsSchema)),\n",
    "    engine=model_engine,\n",
    "    is_async=True\n",
    ")\n",
    "\n",
    "# Define the question to be processed\n",
    "question = \"Calculate the total revenue for Q4 2024 and provide a summary of key highlights in a table.\"\n",
    "\n",
    "# Debugging: Print the constructed prompt before processing\n",
    "constructed_prompt = compute_and_analyze(question)\n",
    "print(\"Constructed Prompt:\")\n",
    "print(constructed_prompt)\n",
    "\n",
    "# Process the prompt with the agent\n",
    "response = await compute_analyze_agent.process(prompt=constructed_prompt)\n",
    "\n",
    "# Display the response\n",
    "print(\"Agent Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from returns.future import Future\n",
    "\n",
    "async def process_agent_response(prompt):\n",
    "    return Future.from_sync(lambda: q1_agent.process(my_prompt(prompt)))\n",
    "\n",
    "response = await process_agent_response(\"What were the key highlights of the Q4 2024 earnings?\").close()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from beta.models.serve.engines import VLLMEngine, OpenAIEngineConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client = mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "oai_config = OpenAIEngineConfig(data={\"temperature\": 0.5, \"max_tokens\": 4096, \"top_p\": 1, \"frequency_penalty\": 0, \"presence_penalty\": 0})\n",
    "vllm_engine = VLLMEngine(config=oai_config, api_key=\"EMPTY\", base_url=\"http://localhost:8000\")\n",
    "\n",
    "\n",
    "llm = LLM(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", engine=vllm_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.models.obj import llm\n",
    "from beta.models.serve.engines import LitServeEngine, OpenAIEngine, OpenRouterEngine, VLLMEngine\n",
    "\n",
    "\n",
    "completion_settings = llm.settings(\n",
    "    temperature=0.5,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    ")\n",
    "\n",
    "# Defaults to OpenRouter\n",
    "# Expects OPENROUTER_API_KEY to be defined in .env\n",
    "gemini_free = llm(\n",
    "    model_name=\"google/gemini-pro-1.5-flash\",\n",
    "    settings=completion_settings,\n",
    ")\n",
    "\n",
    "# If OPENAI_API_KEY, uses { OpenAi | AsyncOpenAI } clients instead of OpenRouter. \n",
    "gpt4o = llm(\n",
    "    model_name=\"openai/o1-mini\",\n",
    "    settings=completion_settings,\n",
    ")\n",
    "\n",
    "# If ANTHROPIC_API_KEY, uses {Anthropic | AsyncAnthopic }\n",
    "sonnet = llm(\n",
    "    model_name=\"anthopic/claude-3.5-sonnet\",\n",
    "    settings = completion_settings,\n",
    ")\n",
    "\n",
    "\n",
    "# Specifying the Engine with OS Model\n",
    "paligemma = llm(\n",
    "    model_name=\"google/paligemma-3b-mix-448\",\n",
    "    engine=LitServeEngine(), \n",
    "    completion_settings=completion_settings\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.tools import CalculatorTool, DataframeTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from beta.agents import BaseAgent, SpeechAgent\n",
    "\n",
    "artifact_df = daft.DataFrame()\n",
    "node_df = daft.DataFrame()\n",
    "document_df = daft.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "earnings = Data.Projects.get(\"Earnings Q4 2024\")\n",
    "knowledge_graph = my_project.Graphs.get(\"latest\")\n",
    "\n",
    "\n",
    "q1_agent = Agent(\n",
    "    llm=paligemma,\n",
    "    tools=[CalculatorTool, DataframeTool],\n",
    "    context=[earnings],\n",
    "    memory={'short':[knowl]},\n",
    ")\n",
    "\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"{{ question}}\"\"\"\n",
    "\n",
    "@prompt\n",
    "def cot(my_prompt,max_steps):\n",
    "    \"\"\"\n",
    "    System: \n",
    "        Using Chain of Thought:\n",
    "        max_steps = {{max_steps}}\n",
    "\n",
    "        for step in max_steps:\n",
    "            Reason about the request and append, \"Therefore\"\n",
    "        \n",
    "        Make a concluding response \n",
    "\n",
    "    User:\n",
    "    {{ my_prompt }}\n",
    "    \"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from datetime import date\n",
    "\n",
    "class QuarterlyEarnings(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents quarterly earnings data for a company.\n",
    "    \"\"\"\n",
    "    company_name: str = Field(..., description=\"Name of the company\")\n",
    "    fiscal_quarter: int = Field(..., ge=1, le=4, description=\"Fiscal quarter (1-4)\")\n",
    "    fiscal_year: int = Field(..., description=\"Fiscal year\")\n",
    "    revenue: float = Field(..., description=\"Total revenue for the quarter\")\n",
    "    net_income: float = Field(..., description=\"Net income for the quarter\")\n",
    "    earnings_per_share: float = Field(..., description=\"Earnings per share\")\n",
    "    report_date: date = Field(..., description=\"Date of the earnings report\")\n",
    "    analyst_expectations_met: Optional[bool] = Field(None, description=\"Whether analyst expectations were met\")\n",
    "    key_highlights: Optional[List[str]] = Field(None, description=\"Key highlights from the earnings report\")\n",
    "\n",
    "\n",
    "response = await my_agent(\n",
    "    prompt=\n",
    "    response_model=[Address], \n",
    "        reponse_model_strict = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
