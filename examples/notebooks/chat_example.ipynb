{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"/teamspace/studios/this_studio/beta/.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"schema\" in \"SchemaWrapper\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"schema\" in \"Metadata\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    }
   ],
   "source": [
    "from beta import Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56538cfe5073497aba5260ea25e5710e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import json\n",
    "\n",
    "\n",
    "def on_file_selected(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        file_content = change['new']\n",
    "        if not file_content:\n",
    "            print(\"No file selected\")\n",
    "            return\n",
    "        \n",
    "        print(\"File content type:\", type(file_content))\n",
    "        print(\"File content:\", file_content)\n",
    "        \n",
    "        # Handle the tuple structure\n",
    "        if isinstance(file_content, tuple) and len(file_content) > 0:\n",
    "            file_data = file_content[0]\n",
    "            file_name = file_data['name']\n",
    "            \n",
    "            print(f\"Selected file: {file_name}\")\n",
    "            print(\"File data type:\", type(file_data))\n",
    "            \n",
    "            try:\n",
    "                # Create the Artifact\n",
    "                artifact = Artifact(files=[file_name])\n",
    "                print(\"Artifact created successfully\")\n",
    "                print(\"Artifact DataFrame:\")\n",
    "                artifact.df.collect().show()\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating Artifact: {str(e)}\")\n",
    "        else:\n",
    "            print(\"Unexpected file content format\")\n",
    "\n",
    "# Create a file upload widget\n",
    "file_upload = widgets.FileUpload(\n",
    "    accept='',  # Accept all file types\n",
    "    multiple=False  # Allow only single file selection\n",
    ")\n",
    "\n",
    "# Display the file upload widget\n",
    "display(file_upload)\n",
    "\n",
    "# Attach the callback to the file upload widget\n",
    "file_upload.observe(on_file_selected, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-21\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.date(datetime.now())\n",
    "print(str(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    }
   ],
   "source": [
    "artifact_repository = f\"/teamspace/uploads/artifacts/payloads/{str(today)}/\"\n",
    "\n",
    "papers = Artifact(files=[\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2401.05459v2.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2401.18059.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2402.01680v2.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2402.01968v1.pdf\"\n",
    "], uri_prefix=artifact_repository)\n",
    "\n",
    "br_23_earnings = Artifact(files=[\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 1Q23 Earnings Release.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 2Q23 Earnings Release.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 3Q23 Earnings Release.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 4Q23 Earnings Release.pdf\"\n",
    "], uri_prefix=artifact_repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: PyMicroPartition::to_table, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: PyMicroPartition::to_table, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table class=\"dataframe\">\n",
       "<thead><tr><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">artifact_uri<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">checksum<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">created_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">extension<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">id<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">inserted_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">mime_type<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">name<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">payload<br />Binary</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">size_bytes<br />Int64</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">type<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">updated_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">version<br />Utf8</th></tr></thead>\n",
       "<tbody>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-21//01J8AD69GAHTTJFHZPY3JKJ93E__BLK 1Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">91f1ec0a9dbc64375b730641fd248101</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:43:55.146166</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J8AD69GAHTTJFHZPY3JKJ93E</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:43:55.146166</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 1Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\x9b\\xcd\\xeef\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1061830</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:43:55.146166</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-21//01J8AD69H86QTEWV7H33XEFX6B__BLK 2Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">413cb79dd3084d282a821f61d53c401c</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:43:55.176378</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J8AD69H86QTEWV7H33XEFX6B</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:43:55.176378</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 2Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\x9b\\xcd\\xeef\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">316186</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:43:55.176378</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-21//01J8AD69HJKQSVPV3S1X4AJD31__BLK 3Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">aea5a59de7f6ebdd8145891af2a0f16c</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:43:55.186777</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J8AD69HJKQSVPV3S1X4AJD31</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:43:55.186777</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 3Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\x9b\\xcd\\xeef\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">321016</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:43:55.186777</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-21//01J8AD69HXWFWZ526CK8JEYP9Q__BLK 4Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">3d6086d1eb1aac9e82b80b86913b751a</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:43:55.197336</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J8AD69HXWFWZ526CK8JEYP9Q</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:43:55.197336</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 4Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\x9b\\xcd\\xeef\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">316432</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T13:43:55.197336</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<small>(Showing first 4 of 4 rows)</small>\n",
       "</div>"
      ],
      "text/plain": [
       "╭──────────────────────┬─────────────────────┬─────────────────────┬────────────┬──────┬─────────────────────┬─────────╮\n",
       "│ artifact_uri         ┆ checksum            ┆ created_at          ┆      …     ┆ type ┆ updated_at          ┆ version │\n",
       "│ ---                  ┆ ---                 ┆ ---                 ┆            ┆ ---  ┆ ---                 ┆ ---     │\n",
       "│ Utf8                 ┆ Utf8                ┆ Utf8                ┆ (7 hidden) ┆ Utf8 ┆ Utf8                ┆ Utf8    │\n",
       "╞══════════════════════╪═════════════════════╪═════════════════════╪════════════╪══════╪═════════════════════╪═════════╡\n",
       "│ /teamspace/uploads/a ┆ 91f1ec0a9dbc64375b7 ┆ 2024-09-21T13:43:55 ┆ …          ┆ file ┆ 2024-09-21T13:43:55 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 30641fd248…         ┆ .146166             ┆            ┆      ┆ .146166             ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ /teamspace/uploads/a ┆ 413cb79dd3084d282a8 ┆ 2024-09-21T13:43:55 ┆ …          ┆ file ┆ 2024-09-21T13:43:55 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 21f61d53c4…         ┆ .176378             ┆            ┆      ┆ .176378             ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ /teamspace/uploads/a ┆ aea5a59de7f6ebdd814 ┆ 2024-09-21T13:43:55 ┆ …          ┆ file ┆ 2024-09-21T13:43:55 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 5891af2a0f…         ┆ .186777             ┆            ┆      ┆ .186777             ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ /teamspace/uploads/a ┆ 3d6086d1eb1aac9e82b ┆ 2024-09-21T13:43:55 ┆ …          ┆ file ┆ 2024-09-21T13:43:55 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 80b86913b7…         ┆ .197336             ┆            ┆      ┆ .197336             ┆         │\n",
       "╰──────────────────────┴─────────────────────┴─────────────────────┴────────────┴──────┴─────────────────────┴─────────╯\n",
       "\n",
       "(Showing first 4 of 4 rows)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.df.collect()\n",
    "br_23_earnings.df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Artifact Persistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta import Agent\n",
    "from vllm import LLM\n",
    "from beta.tools.obj import CalculatorTool, DataFrameTool\n",
    "from beta.models.serve.engines import VLLMEngine\n",
    "from beta.models.serve.engines import OpenAIEngineConfig\n",
    "from mlflow.client import MlflowClient\n",
    "from daft import DataFrame\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/models \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"city\": \"N/A\",\n",
      "  \"capital\": \"Africa is a continent with 54 countries and does not have a capital. Each country within Africa has its own capital city.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine, OpenAIEngineConfig\n",
    "mlflow.set_experiment(\"Dratos AI\")\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model\", \"gpt-4o\")\n",
    "    mlflow.log_param(\"temperature\", 0.5)\n",
    "    mlflow.log_param(\"max_tokens\", 4096)\n",
    "    mlflow.log_param(\"top_p\", 1)\n",
    "    mlflow.log_param(\"frequency_penalty\", 0)\n",
    "    mlflow.log_param(\"presence_penalty\", 0)\n",
    "    prompt = \"What is the capital of Africa?\"\n",
    "    mlflow.log_param(\"prompt\", prompt)\n",
    "\n",
    "    config = OpenAIEngineConfig(data={\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"top_p\": 1,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    })\n",
    "    engine = OpenAIEngine(config=config)\n",
    "    response = await engine.generate_structured(prompt, structure=\"{city: str, capital: str}\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.prompts import prompt\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"{{ question }}\"\"\"\n",
    "\n",
    "@prompt\n",
    "def cot(my_prompt, max_steps):\n",
    "    \"\"\"\n",
    "    System: \n",
    "        Using Chain of Thought:\n",
    "        max_steps = {{max_steps}}\n",
    "\n",
    "        for step in max_steps:\n",
    "            Reason about the request and append, \"Therefore\"\n",
    "        \n",
    "        Make a concluding response \n",
    "\n",
    "    User:\n",
    "    {{ my_prompt }}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from datetime import date\n",
    "from ray import serve\n",
    "\n",
    "@serve.deployment(name=\"QuarterlyEarningsDeployment\")\n",
    "class QuarterlyEarningsDeployment(BaseModel):\n",
    "    company_name: str = Field(..., description=\"Name of the company\")\n",
    "    fiscal_quarter: int = Field(..., ge=1, le=4, description=\"Fiscal quarter (1-4)\")\n",
    "    fiscal_year: int = Field(..., description=\"Fiscal year\")\n",
    "    revenue: float = Field(..., description=\"Total revenue for the quarter\")\n",
    "    net_income: float = Field(..., description=\"Net income for the quarter\")\n",
    "    earnings_per_share: float = Field(..., description=\"Earnings per share\")\n",
    "    report_date: date = Field(..., description=\"Date of the earnings report\")\n",
    "    analyst_expectations_met: Optional[bool] = Field(None, description=\"Whether analyst expectations were met\")\n",
    "    key_highlights: Optional[List[str]] = Field(None, description=\"Key highlights from the earnings report\")\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return \"QuarterlyEarnings deployment is working\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine\n",
    "\n",
    "def openai_engine_serializer(engine):\n",
    "    # Return the arguments needed to reconstruct the engine\n",
    "    return (engine.model_name, engine.config)\n",
    "\n",
    "def openai_engine_deserializer(model_name, config):\n",
    "    # Reconstruct the engine\n",
    "    return OpenAIEngine(model_name=model_name, config=config)\n",
    "\n",
    "# Register the custom serializer with Ray\n",
    "ray.util.register_serializer(\n",
    "    OpenAIEngine,\n",
    "    serializer=openai_engine_serializer,\n",
    "    deserializer=openai_engine_deserializer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import inspect\n",
    "from pydantic import BaseModel\n",
    "import daft\n",
    "from ray import serve\n",
    "from typing import get_origin, get_args\n",
    "\n",
    "def pydantic_to_daft_schema(model_class):\n",
    "    if isinstance(model_class, serve.Deployment):\n",
    "        # This is a Ray Serve deployment\n",
    "        model_class = model_class.func_or_class\n",
    "\n",
    "    if not inspect.isclass(model_class) or not issubclass(model_class, BaseModel):\n",
    "        raise ValueError(\"Input must be a Pydantic model class or a Ray Serve deployment of a Pydantic model\")\n",
    "\n",
    "    field_dict = {}\n",
    "    for name, field in model_class.model_fields.items():\n",
    "        if field.annotation == str:\n",
    "            field_dict[name] = daft.DataType.string()\n",
    "        elif field.annotation == int:\n",
    "            field_dict[name] = daft.DataType.int64()\n",
    "        elif field.annotation == float:\n",
    "            field_dict[name] = daft.DataType.float64()\n",
    "        elif field.annotation == bool:\n",
    "            field_dict[name] = daft.DataType.boolean()\n",
    "        elif field.annotation == datetime.date:\n",
    "            field_dict[name] = daft.DataType.date()\n",
    "        elif get_origin(field.annotation) == list and get_args(field.annotation)[0] == str:\n",
    "            field_dict[name] = daft.DataType.list(daft.DataType.string())\n",
    "        else:\n",
    "            field_dict[name] = daft.DataType.python()  # Fallback for complex types\n",
    "    return daft.DataType.struct(field_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 13:43:57,912\tINFO worker.py:1601 -- Connecting to existing Ray cluster at address: 10.192.12.246:6380...\n",
      "2024-09-21 13:43:57,918\tINFO worker.py:1786 -- Connected to Ray cluster.\n",
      "INFO 2024-09-21 13:43:57,936 serve 372224 api.py:259 - Connecting to existing Serve app in namespace \"serve\". New http options will not be applied.\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:root:Lancedb client connected: LanceDBConnection(/teamspace/studios/this_studio/.lancedb)\n",
      "INFO:root:Agent Q1 Agent called with prompt: What were the key highlights of the Q4 2024 earnings?\n",
      "INFO:root:Agent status set to processing\n",
      "INFO:root:Sending request to model\n",
      "INFO:root:Prompt: What were the key highlights of the Q4 2024 earnings?\n",
      "INFO:root:Storing artifact in LanceDB: <Artifact with 4 files>\n",
      "INFO:daft.runners.pyrunner:Using python executor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0df9f931e24017bfd42e37bbba6aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Project [Stage:1]:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::eval_expression_list, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    }
   ],
   "source": [
    "from daft import Schema\n",
    "import os\n",
    "import daft\n",
    "import json\n",
    "import ray\n",
    "from ray import serve\n",
    "from beta.agents.agent import Agent, Metadata, SchemaWrapper\n",
    "from beta.tools.obj.calculator_tool import CalculatorTool\n",
    "from beta.tools.obj.dataframe_tool import DataFrameTool\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine, OpenAIEngineConfig\n",
    "\n",
    "# Initialize Ray and Serve\n",
    "if not ray.is_initialized():\n",
    "    ray.init(address=\"127.0.0.1:6380\", ignore_reinit_error=True)\n",
    "serve.start()\n",
    "\n",
    "# Create OpenAIEngine instances\n",
    "config = OpenAIEngineConfig(\n",
    "    data={\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"top_p\": 1,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    }\n",
    ")\n",
    "\n",
    "embedding_config = OpenAIEngineConfig(\n",
    "    data={\n",
    "        \"model\": \"text-embedding-ada-002\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"top_p\": 1,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    }\n",
    ")\n",
    "model_engine = OpenAIEngine(config=config)\n",
    "embedding_engine = OpenAIEngine(config=embedding_config)\n",
    "stt_engine = OpenAIEngine(config=config)\n",
    "\n",
    "# Create the Agent\n",
    "q1_agent = Agent(\n",
    "    name=\"Q1 Agent\",\n",
    "    model=model_engine,\n",
    "    embedding=embedding_engine,\n",
    "    stt=stt_engine,\n",
    "    tools=[CalculatorTool, DataFrameTool],\n",
    "    engine=model_engine,\n",
    "    artifacts=[br_23_earnings],\n",
    "    is_async=True,\n",
    ")\n",
    "\n",
    "from beta.prompts import prompt\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"What were the key highlights of the Q4 2024 earnings?\"\"\"\n",
    "\n",
    "response = await q1_agent.process(prompt=my_prompt())\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   import lancedb\n",
    "\n",
    "   try:\n",
    "       db = lancedb.connect(\"~/.lancedb\")\n",
    "       db.table_names()\n",
    "       print(\"Successfully connected to LanceDB\")\n",
    "       print(db.table_names())\n",
    "   except Exception as e:\n",
    "       print(f\"Failed to connect to LanceDB: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Cell: Using CalculatorTool and DataFrameTool with Agent\n",
    "\n",
    "from beta.tools import CalculatorTool, DataFrameTool\n",
    "from beta.agents import Agent\n",
    "from beta.prompts import prompt\n",
    "\n",
    "# Define a new prompt that leverages both tools\n",
    "@prompt\n",
    "def compute_and_analyze(question):\n",
    "    \"\"\"\n",
    "    You are an intelligent assistant equipped with Calculator and DataFrame tools.\n",
    "    \n",
    "    Task:\n",
    "    - Calculate the total revenue for Q4 2024.\n",
    "    - Provide a summary of key highlights in a table format.\n",
    "    \n",
    "    User Question:\n",
    "    {{ question }}\n",
    "    \"\"\"\n",
    "\n",
    "# Initialize the Agent with CalculatorTool and DataFrameTool\n",
    "compute_analyze_agent = Agent(\n",
    "    name=\"ComputeAnalyzeAgent\",\n",
    "    model=model_engine,          # Ensure model_engine is defined in your environment\n",
    "    embedding=embedding_engine,  # Ensure embedding_engine is defined in your environment\n",
    "    stt=stt_engine,              # Ensure stt_engine is defined in your environment\n",
    "    tools=[CalculatorTool, DataFrameTool],\n",
    "    metadata=Metadata(schema=SchemaWrapper(schema=QuarterlyEarningsSchema)),\n",
    "    engine=model_engine,\n",
    "    is_async=True\n",
    ")\n",
    "\n",
    "# Define the question to be processed\n",
    "question = \"Calculate the total revenue for Q4 2024 and provide a summary of key highlights in a table.\"\n",
    "\n",
    "# Debugging: Print the constructed prompt before processing\n",
    "constructed_prompt = compute_and_analyze(question)\n",
    "print(\"Constructed Prompt:\")\n",
    "print(constructed_prompt)\n",
    "\n",
    "# Process the prompt with the agent\n",
    "response = await compute_analyze_agent.process(prompt=constructed_prompt)\n",
    "\n",
    "# Display the response\n",
    "print(\"Agent Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from returns.future import Future\n",
    "\n",
    "async def process_agent_response(prompt):\n",
    "    return Future.from_sync(lambda: q1_agent.process(my_prompt(prompt)))\n",
    "\n",
    "response = await process_agent_response(\"What were the key highlights of the Q4 2024 earnings?\").close()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from beta.models.serve.engines import VLLMEngine, OpenAIEngineConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client = mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "oai_config = OpenAIEngineConfig(data={\"temperature\": 0.5, \"max_tokens\": 4096, \"top_p\": 1, \"frequency_penalty\": 0, \"presence_penalty\": 0})\n",
    "vllm_engine = VLLMEngine(config=oai_config, api_key=\"EMPTY\", base_url=\"http://localhost:8000\")\n",
    "\n",
    "\n",
    "llm = LLM(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", engine=vllm_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.models.obj import llm\n",
    "from beta.models.serve.engines import LitServeEngine, OpenAIEngine, OpenRouterEngine, VLLMEngine\n",
    "\n",
    "\n",
    "completion_settings = llm.settings(\n",
    "    temperature=0.5,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    ")\n",
    "\n",
    "# Defaults to OpenRouter\n",
    "# Expects OPENROUTER_API_KEY to be defined in .env\n",
    "gemini_free = llm(\n",
    "    model_name=\"google/gemini-pro-1.5-flash\",\n",
    "    settings=completion_settings,\n",
    ")\n",
    "\n",
    "# If OPENAI_API_KEY, uses { OpenAi | AsyncOpenAI } clients instead of OpenRouter. \n",
    "gpt4o = llm(\n",
    "    model_name=\"openai/o1-mini\",\n",
    "    settings=completion_settings,\n",
    ")\n",
    "\n",
    "# If ANTHROPIC_API_KEY, uses {Anthropic | AsyncAnthopic }\n",
    "sonnet = llm(\n",
    "    model_name=\"anthopic/claude-3.5-sonnet\",\n",
    "    settings = completion_settings,\n",
    ")\n",
    "\n",
    "\n",
    "# Specifying the Engine with OS Model\n",
    "paligemma = llm(\n",
    "    model_name=\"google/paligemma-3b-mix-448\",\n",
    "    engine=LitServeEngine(), \n",
    "    completion_settings=completion_settings\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.tools import CalculatorTool, DataframeTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from beta.agents import BaseAgent, SpeechAgent\n",
    "\n",
    "artifact_df = daft.DataFrame()\n",
    "node_df = daft.DataFrame()\n",
    "document_df = daft.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "earnings = Data.Projects.get(\"Earnings Q4 2024\")\n",
    "knowledge_graph = my_project.Graphs.get(\"latest\")\n",
    "\n",
    "\n",
    "q1_agent = Agent(\n",
    "    llm=paligemma,\n",
    "    tools=[CalculatorTool, DataframeTool],\n",
    "    context=[earnings],\n",
    "    memory={'short':[knowl]},\n",
    ")\n",
    "\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"{{ question}}\"\"\"\n",
    "\n",
    "@prompt\n",
    "def cot(my_prompt,max_steps):\n",
    "    \"\"\"\n",
    "    System: \n",
    "        Using Chain of Thought:\n",
    "        max_steps = {{max_steps}}\n",
    "\n",
    "        for step in max_steps:\n",
    "            Reason about the request and append, \"Therefore\"\n",
    "        \n",
    "        Make a concluding response \n",
    "\n",
    "    User:\n",
    "    {{ my_prompt }}\n",
    "    \"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from datetime import date\n",
    "\n",
    "class QuarterlyEarnings(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents quarterly earnings data for a company.\n",
    "    \"\"\"\n",
    "    company_name: str = Field(..., description=\"Name of the company\")\n",
    "    fiscal_quarter: int = Field(..., ge=1, le=4, description=\"Fiscal quarter (1-4)\")\n",
    "    fiscal_year: int = Field(..., description=\"Fiscal year\")\n",
    "    revenue: float = Field(..., description=\"Total revenue for the quarter\")\n",
    "    net_income: float = Field(..., description=\"Net income for the quarter\")\n",
    "    earnings_per_share: float = Field(..., description=\"Earnings per share\")\n",
    "    report_date: date = Field(..., description=\"Date of the earnings report\")\n",
    "    analyst_expectations_met: Optional[bool] = Field(None, description=\"Whether analyst expectations were met\")\n",
    "    key_highlights: Optional[List[str]] = Field(None, description=\"Key highlights from the earnings report\")\n",
    "\n",
    "\n",
    "response = await my_agent(\n",
    "    prompt=\n",
    "    response_model=[Address], \n",
    "        reponse_model_strict = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
