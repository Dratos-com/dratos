{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"/teamspace/studios/this_studio/beta/.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta import Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c506edbc820548c6a9e530bcfd239520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import json\n",
    "\n",
    "\n",
    "def on_file_selected(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        file_content = change['new']\n",
    "        if not file_content:\n",
    "            print(\"No file selected\")\n",
    "            return\n",
    "        \n",
    "        print(\"File content type:\", type(file_content))\n",
    "        print(\"File content:\", file_content)\n",
    "        \n",
    "        # Handle the tuple structure\n",
    "        if isinstance(file_content, tuple) and len(file_content) > 0:\n",
    "            file_data = file_content[0]\n",
    "            file_name = file_data['name']\n",
    "            \n",
    "            print(f\"Selected file: {file_name}\")\n",
    "            print(\"File data type:\", type(file_data))\n",
    "            \n",
    "            try:\n",
    "                # Create the Artifact\n",
    "                artifact = Artifact(files=[file_name])\n",
    "                print(\"Artifact created successfully\")\n",
    "                print(\"Artifact DataFrame:\")\n",
    "                artifact.df.collect().show()\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating Artifact: {str(e)}\")\n",
    "        else:\n",
    "            print(\"Unexpected file content format\")\n",
    "\n",
    "# Create a file upload widget\n",
    "file_upload = widgets.FileUpload(\n",
    "    accept='',  # Accept all file types\n",
    "    multiple=False  # Allow only single file selection\n",
    ")\n",
    "\n",
    "# Display the file upload widget\n",
    "display(file_upload)\n",
    "\n",
    "# Attach the callback to the file upload widget\n",
    "file_upload.observe(on_file_selected, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-20\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.date(datetime.now())\n",
    "print(str(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    }
   ],
   "source": [
    "artifact_repository = f\"/teamspace/uploads/artifacts/payloads/{str(today)}/\"\n",
    "\n",
    "papers = Artifact(files=[\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2401.05459v2.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2401.18059.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2402.01680v2.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2402.01968v1.pdf\"\n",
    "], uri_prefix=artifact_repository)\n",
    "\n",
    "br_23_earnings = Artifact(files=[\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 1Q23 Earnings Release.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 2Q23 Earnings Release.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 3Q23 Earnings Release.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 4Q23 Earnings Release.pdf\"\n",
    "], uri_prefix=artifact_repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: PyMicroPartition::to_table, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: PyMicroPartition::to_table, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table class=\"dataframe\">\n",
       "<thead><tr><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">artifact_uri<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">checksum<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">created_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">extension<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">id<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">inserted_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">mime_type<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">name<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">payload<br />Binary</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">size_bytes<br />Int64</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">type<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">updated_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">version<br />Utf8</th></tr></thead>\n",
       "<tbody>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-20//01J88BK5DRZ0Y8ZP9R74DBZKQM__BLK 1Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">91f1ec0a9dbc64375b730641fd248101</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T18:37:30.936898</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J88BK5DRZ0Y8ZP9R74DBZKQM</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T18:37:30.936898</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 1Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xea\\xc0\\xedf\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1061830</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T18:37:30.936898</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-20//01J88BK5EN10ZJATSW58DF1460__BLK 2Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">413cb79dd3084d282a821f61d53c401c</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T18:37:30.965706</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J88BK5EN10ZJATSW58DF1460</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T18:37:30.965706</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 2Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xea\\xc0\\xedf\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">316186</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T18:37:30.965706</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-20//01J88BK5EZ12VYKGG1SFQG9MQA__BLK 3Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">aea5a59de7f6ebdd8145891af2a0f16c</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T18:37:30.975278</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J88BK5EZ12VYKGG1SFQG9MQA</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T18:37:30.975278</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 3Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xea\\xc0\\xedf\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">321016</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T18:37:30.975278</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-20//01J88BK5F9KQ37GV5AREMMVFKT__BLK 4Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">3d6086d1eb1aac9e82b80b86913b751a</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T18:37:30.985618</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J88BK5F9KQ37GV5AREMMVFKT</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T18:37:30.985618</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 4Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xea\\xc0\\xedf\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">316432</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-20T18:37:30.985618</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<small>(Showing first 4 of 4 rows)</small>\n",
       "</div>"
      ],
      "text/plain": [
       "╭──────────────────────┬─────────────────────┬─────────────────────┬────────────┬──────┬─────────────────────┬─────────╮\n",
       "│ artifact_uri         ┆ checksum            ┆ created_at          ┆      …     ┆ type ┆ updated_at          ┆ version │\n",
       "│ ---                  ┆ ---                 ┆ ---                 ┆            ┆ ---  ┆ ---                 ┆ ---     │\n",
       "│ Utf8                 ┆ Utf8                ┆ Utf8                ┆ (7 hidden) ┆ Utf8 ┆ Utf8                ┆ Utf8    │\n",
       "╞══════════════════════╪═════════════════════╪═════════════════════╪════════════╪══════╪═════════════════════╪═════════╡\n",
       "│ /teamspace/uploads/a ┆ 91f1ec0a9dbc64375b7 ┆ 2024-09-20T18:37:30 ┆ …          ┆ file ┆ 2024-09-20T18:37:30 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 30641fd248…         ┆ .936898             ┆            ┆      ┆ .936898             ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ /teamspace/uploads/a ┆ 413cb79dd3084d282a8 ┆ 2024-09-20T18:37:30 ┆ …          ┆ file ┆ 2024-09-20T18:37:30 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 21f61d53c4…         ┆ .965706             ┆            ┆      ┆ .965706             ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ /teamspace/uploads/a ┆ aea5a59de7f6ebdd814 ┆ 2024-09-20T18:37:30 ┆ …          ┆ file ┆ 2024-09-20T18:37:30 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 5891af2a0f…         ┆ .975278             ┆            ┆      ┆ .975278             ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ /teamspace/uploads/a ┆ 3d6086d1eb1aac9e82b ┆ 2024-09-20T18:37:30 ┆ …          ┆ file ┆ 2024-09-20T18:37:30 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 80b86913b7…         ┆ .985618             ┆            ┆      ┆ .985618             ┆         │\n",
       "╰──────────────────────┴─────────────────────┴─────────────────────┴────────────┴──────┴─────────────────────┴─────────╯\n",
       "\n",
       "(Showing first 4 of 4 rows)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.df.collect()\n",
    "br_23_earnings.df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Artifact Persistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"schema\" in \"SchemaWrapper\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"schema\" in \"Metadata\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 09-20 18:37:42 _custom_ops.py:17] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')\n"
     ]
    }
   ],
   "source": [
    "from beta.agents import Agent\n",
    "from beta.models.obj.model_object import VLLM\n",
    "from vllm import LLM\n",
    "from beta.tools.obj import CalculatorTool, DataFrameTool\n",
    "from beta.models.serve.engines import VLLMEngine\n",
    "from beta.models.serve.engines import OpenAIEngineConfig\n",
    "from mlflow.client import MlflowClient\n",
    "from daft import DataFrame\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"city\": null,\n",
      "  \"capital\": \"Africa is a continent, not a country, so it does not have a capital. However, major cities in Africa include Cairo, Nairobi, Lagos, and Johannesburg.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine, OpenAIEngineConfig\n",
    "mlflow.set_experiment(\"Dratos AI\")\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model\", \"gpt-4o\")\n",
    "    mlflow.log_param(\"temperature\", 0.5)\n",
    "    mlflow.log_param(\"max_tokens\", 4096)\n",
    "    mlflow.log_param(\"top_p\", 1)\n",
    "    mlflow.log_param(\"frequency_penalty\", 0)\n",
    "    mlflow.log_param(\"presence_penalty\", 0)\n",
    "    prompt = \"What is the capital of Africa?\"\n",
    "    mlflow.log_param(\"prompt\", prompt)\n",
    "\n",
    "    config = OpenAIEngineConfig(data={\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"top_p\": 1,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    })\n",
    "    engine = OpenAIEngine(config=config)\n",
    "    response = await engine.generate_structured(prompt, structure=\"{city: str, capital: str}\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.prompts import prompt\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"{{ question }}\"\"\"\n",
    "\n",
    "@prompt\n",
    "def cot(my_prompt, max_steps):\n",
    "    \"\"\"\n",
    "    System: \n",
    "        Using Chain of Thought:\n",
    "        max_steps = {{max_steps}}\n",
    "\n",
    "        for step in max_steps:\n",
    "            Reason about the request and append, \"Therefore\"\n",
    "        \n",
    "        Make a concluding response \n",
    "\n",
    "    User:\n",
    "    {{ my_prompt }}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from datetime import date\n",
    "from ray import serve\n",
    "@serve.deployment(name=\"Test0\")\n",
    "class QuarterlyEarnings(BaseModel):\n",
    "    company_name: str = Field(..., description=\"Name of the company\")\n",
    "    fiscal_quarter: int = Field(..., ge=1, le=4, description=\"Fiscal quarter (1-4)\")\n",
    "    fiscal_year: int = Field(..., description=\"Fiscal year\")\n",
    "    revenue: float = Field(..., description=\"Total revenue for the quarter\")\n",
    "    net_income: float = Field(..., description=\"Net income for the quarter\")\n",
    "    earnings_per_share: float = Field(..., description=\"Earnings per share\")\n",
    "    report_date: date = Field(..., description=\"Date of the earnings report\")\n",
    "    analyst_expectations_met: Optional[bool] = Field(None, description=\"Whether analyst expectations were met\")\n",
    "    key_highlights: Optional[List[str]] = Field(None, description=\"Key highlights from the earnings report\")\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return \"QuarterlyEarnings deployment is working\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine\n",
    "\n",
    "def openai_engine_serializer(engine):\n",
    "    # Return the arguments needed to reconstruct the engine\n",
    "    return (engine.model_name, engine.config)\n",
    "\n",
    "def openai_engine_deserializer(model_name, config):\n",
    "    # Reconstruct the engine\n",
    "    return OpenAIEngine(model_name=model_name, config=config)\n",
    "\n",
    "# Register the custom serializer with Ray\n",
    "ray.util.register_serializer(\n",
    "    OpenAIEngine,\n",
    "    serializer=openai_engine_serializer,\n",
    "    deserializer=openai_engine_deserializer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import inspect\n",
    "from pydantic import BaseModel\n",
    "import daft\n",
    "from ray import serve\n",
    "from typing import get_origin, get_args\n",
    "\n",
    "def pydantic_to_daft_schema(model_class):\n",
    "    if isinstance(model_class, serve.Deployment):\n",
    "        # This is a Ray Serve deployment\n",
    "        model_class = model_class.func_or_class\n",
    "\n",
    "    if not inspect.isclass(model_class) or not issubclass(model_class, BaseModel):\n",
    "        raise ValueError(\"Input must be a Pydantic model class or a Ray Serve deployment of a Pydantic model\")\n",
    "\n",
    "    field_dict = {}\n",
    "    for name, field in model_class.model_fields.items():\n",
    "        if field.annotation == str:\n",
    "            field_dict[name] = daft.DataType.string()\n",
    "        elif field.annotation == int:\n",
    "            field_dict[name] = daft.DataType.int64()\n",
    "        elif field.annotation == float:\n",
    "            field_dict[name] = daft.DataType.float64()\n",
    "        elif field.annotation == bool:\n",
    "            field_dict[name] = daft.DataType.boolean()\n",
    "        elif field.annotation == datetime.date:\n",
    "            field_dict[name] = daft.DataType.date()\n",
    "        elif get_origin(field.annotation) == list and get_args(field.annotation)[0] == str:\n",
    "            field_dict[name] = daft.DataType.list(daft.DataType.string())\n",
    "        else:\n",
    "            field_dict[name] = daft.DataType.python()  # Fallback for complex types\n",
    "    return daft.DataType.struct(field_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Deployment.__call__() got an unexpected keyword argument 'company_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 54\u001b[0m\n\u001b[1;32m      8\u001b[0m sample_data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     {\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompany_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mABC Corp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     }\n\u001b[1;32m     51\u001b[0m ]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Convert sample data to QuarterlyEarnings instances\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m quarterly_earnings_instances \u001b[38;5;241m=\u001b[39m [QuarterlyEarnings(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mitem) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sample_data]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Create a Daft DataFrame from Pydantic models\u001b[39;00m\n\u001b[1;32m     57\u001b[0m revenue_df \u001b[38;5;241m=\u001b[39m daft\u001b[38;5;241m.\u001b[39mfrom_pydantic(QuarterlyEarnings, quarterly_earnings_instances)\n",
      "Cell \u001b[0;32mIn[15], line 54\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m sample_data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     {\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompany_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mABC Corp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     }\n\u001b[1;32m     51\u001b[0m ]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Convert sample data to QuarterlyEarnings instances\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m quarterly_earnings_instances \u001b[38;5;241m=\u001b[39m [\u001b[43mQuarterlyEarnings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sample_data]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Create a Daft DataFrame from Pydantic models\u001b[39;00m\n\u001b[1;32m     57\u001b[0m revenue_df \u001b[38;5;241m=\u001b[39m daft\u001b[38;5;241m.\u001b[39mfrom_pydantic(QuarterlyEarnings, quarterly_earnings_instances)\n",
      "\u001b[0;31mTypeError\u001b[0m: Deployment.__call__() got an unexpected keyword argument 'company_name'"
     ]
    }
   ],
   "source": [
    "# New Cell: Generate Sample Revenue DataFrames\n",
    "\n",
    "from datetime import date\n",
    "from pydantic import BaseModel\n",
    "import daft\n",
    "\n",
    "# Define sample data for Q4 2024\n",
    "sample_data = [\n",
    "    {\n",
    "        \"company_name\": \"ABC Corp\",\n",
    "        \"fiscal_quarter\": 4,\n",
    "        \"fiscal_year\": 2024,\n",
    "        \"revenue\": 500000.0,\n",
    "        \"net_income\": 120000.0,\n",
    "        \"earnings_per_share\": 2.5,\n",
    "        \"report_date\": date(2024, 10, 31),\n",
    "        \"analyst_expectations_met\": True,\n",
    "        \"key_highlights\": [\n",
    "            \"Increased sales in electronics\",\n",
    "            \"Expanded to new markets\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"ABC Corp\",\n",
    "        \"fiscal_quarter\": 4,\n",
    "        \"fiscal_year\": 2024,\n",
    "        \"revenue\": 600000.0,\n",
    "        \"net_income\": 150000.0,\n",
    "        \"earnings_per_share\": 3.0,\n",
    "        \"report_date\": date(2024, 11, 30),\n",
    "        \"analyst_expectations_met\": False,\n",
    "        \"key_highlights\": [\n",
    "            \"Supply chain disruptions\",\n",
    "            \"Higher marketing expenses\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"ABC Corp\",\n",
    "        \"fiscal_quarter\": 4,\n",
    "        \"fiscal_year\": 2024,\n",
    "        \"revenue\": 550000.0,\n",
    "        \"net_income\": 130000.0,\n",
    "        \"earnings_per_share\": 2.8,\n",
    "        \"report_date\": date(2024, 12, 31),\n",
    "        \"analyst_expectations_met\": True,\n",
    "        \"key_highlights\": [\n",
    "            \"Improved operational efficiencies\",\n",
    "            \"New product launch success\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert sample data to QuarterlyEarnings instances\n",
    "quarterly_earnings_instances = [QuarterlyEarnings(**item) for item in sample_data]\n",
    "\n",
    "# Create a Daft DataFrame from Pydantic models\n",
    "revenue_df = daft.from_pydantic(QuarterlyEarnings, quarterly_earnings_instances)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Sample Revenue DataFrame:\")\n",
    "revenue_df.collect().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 09-20 17:14:13 _custom_ops.py:17] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"schema\" in \"SchemaWrapper\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"schema\" in \"Metadata\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "2024-09-20 17:14:17,072\tINFO worker.py:1461 -- Using address \"auto\" # Ray cluster address; 'auto' to auto-detect set in the environment variable RAY_ADDRESS\n",
      "2024-09-20 17:14:17,073\tINFO worker.py:1601 -- Connecting to existing Ray cluster at address: \"auto\" # Ray cluster address; 'auto' to auto-detect...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Port is not specified for address \"auto\" # Ray cluster address; 'auto' to auto-detect",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbeta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengines\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEngine, OpenAIEngineConfig\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Initialize Ray and Serve\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_reinit_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m serve\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Create OpenAIEngine instances\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/ray/_private/worker.py:1742\u001b[0m, in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, labels, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, logging_config, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001b[0m\n\u001b[1;32m   1730\u001b[0m ray_params \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39m_private\u001b[38;5;241m.\u001b[39mparameter\u001b[38;5;241m.\u001b[39mRayParams(\n\u001b[1;32m   1731\u001b[0m     node_ip_address\u001b[38;5;241m=\u001b[39m_node_ip_address,\n\u001b[1;32m   1732\u001b[0m     gcs_address\u001b[38;5;241m=\u001b[39mgcs_address,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     metrics_export_port\u001b[38;5;241m=\u001b[39m_metrics_export_port,\n\u001b[1;32m   1740\u001b[0m )\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1742\u001b[0m     _global_node \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_private\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m        \u001b[49m\u001b[43mray_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshutdown_at_exit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspawn_reaper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnect_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mConnectionError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m):\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcs_address \u001b[38;5;241m==\u001b[39m ray\u001b[38;5;241m.\u001b[39m_private\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mread_ray_address(_temp_dir):\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/ray/_private/node.py:158\u001b[0m, in \u001b[0;36mNode.__init__\u001b[0;34m(self, ray_params, head, shutdown_at_exit, spawn_reaper, connect_only, default_worker, ray_init_cluster)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gcs_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_ip_port\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_gcs_client()\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Register the temp dir.\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/ray/_private/node.py:394\u001b[0m, in \u001b[0;36mNode.validate_ip_port\u001b[0;34m(ip_port)\u001b[0m\n\u001b[1;32m    392\u001b[0m _, _, port \u001b[38;5;241m=\u001b[39m ip_port\u001b[38;5;241m.\u001b[39mrpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m port \u001b[38;5;241m==\u001b[39m ip_port:\n\u001b[0;32m--> 394\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPort is not specified for address \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mip_port\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    396\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(port)\n",
      "\u001b[0;31mValueError\u001b[0m: Port is not specified for address \"auto\" # Ray cluster address; 'auto' to auto-detect"
     ]
    }
   ],
   "source": [
    "from daft import Schema\n",
    "import daft\n",
    "import json\n",
    "import ray\n",
    "from ray import serve\n",
    "from beta.agents.agent import Agent, Metadata, SchemaWrapper\n",
    "from beta.tools.obj.calculator_tool import CalculatorTool\n",
    "from beta.tools.obj.dataframe_tool import DataFrameTool\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine, OpenAIEngineConfig\n",
    "\n",
    "# Initialize Ray and Serve\n",
    "ray.init(ignore_reinit_error=True)\n",
    "serve.start()\n",
    "\n",
    "# Create OpenAIEngine instances\n",
    "config = OpenAIEngineConfig(\n",
    "    \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    \"temperature\": 0.5,\n",
    "    \"max_tokens\": 4096,\n",
    "    \"top_p\": 1,\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"presence_penalty\": 0\n",
    "})  \n",
    "model_engine = OpenAIEngine(model_name=\"gpt-4o\", config=config)\n",
    "embedding_engine = OpenAIEngine(model_name=\"gpt-4o\", config=config)\n",
    "stt_engine = OpenAIEngine(model_name=\"gpt-4o\", config=config)\n",
    "\n",
    "# QuarterlyEarnings as a DataFrame Schema\n",
    "QuarterlyEarningsSchema = pydantic_to_daft_schema(QuarterlyEarnings)\n",
    "\n",
    "# Create the Agent\n",
    "q1_agent = Agent(\n",
    "    name=\"Q1 Agent\",\n",
    "    model=model_engine,\n",
    "    embedding=embedding_engine,\n",
    "    stt=stt_engine,\n",
    "    tools=[CalculatorTool, DataFrameTool],\n",
    "    metadata=Metadata(schema=SchemaWrapper(schema=QuarterlyEarningsSchema)),\n",
    "    engine=model_engine,\n",
    "    memory=[earnings],\n",
    "    is_async=True\n",
    ")\n",
    "\n",
    "from beta.prompts import prompt\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"What were the key highlights of the Q4 2024 earnings?\"\"\"\n",
    "\n",
    "response = await q1_agent.process(prompt=my_prompt())\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Cell: Using CalculatorTool and DataFrameTool with Agent\n",
    "\n",
    "from beta.tools import CalculatorTool, DataFrameTool\n",
    "from beta.agents import Agent\n",
    "from beta.prompts import prompt\n",
    "\n",
    "# Define a new prompt that leverages both tools\n",
    "@prompt\n",
    "def compute_and_analyze(question):\n",
    "    \"\"\"\n",
    "    You are an intelligent assistant equipped with Calculator and DataFrame tools.\n",
    "    \n",
    "    Task:\n",
    "    - Calculate the total revenue for Q4 2024.\n",
    "    - Provide a summary of key highlights in a table format.\n",
    "    \n",
    "    User Question:\n",
    "    {{ question }}\n",
    "    \"\"\"\n",
    "\n",
    "# Initialize the Agent with CalculatorTool and DataFrameTool\n",
    "compute_analyze_agent = Agent(\n",
    "    name=\"ComputeAnalyzeAgent\",\n",
    "    model=model_engine,          # Ensure model_engine is defined in your environment\n",
    "    embedding=embedding_engine,  # Ensure embedding_engine is defined in your environment\n",
    "    stt=stt_engine,              # Ensure stt_engine is defined in your environment\n",
    "    tools=[CalculatorTool, DataFrameTool],\n",
    "    metadata=Metadata(schema=SchemaWrapper(schema=QuarterlyEarningsSchema)),\n",
    "    engine=model_engine,\n",
    "    is_async=True\n",
    ")\n",
    "\n",
    "# Define the question to be processed\n",
    "question = \"Calculate the total revenue for Q4 2024 and provide a summary of key highlights in a table.\"\n",
    "\n",
    "# Debugging: Print the constructed prompt before processing\n",
    "constructed_prompt = compute_and_analyze(question)\n",
    "print(\"Constructed Prompt:\")\n",
    "print(constructed_prompt)\n",
    "\n",
    "# Process the prompt with the agent\n",
    "response = await compute_analyze_agent.process(prompt=constructed_prompt)\n",
    "\n",
    "# Display the response\n",
    "print(\"Agent Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from returns.future import Future\n",
    "\n",
    "async def process_agent_response(prompt):\n",
    "    return Future.from_sync(lambda: q1_agent.process(my_prompt(prompt)))\n",
    "\n",
    "response = await process_agent_response(\"What were the key highlights of the Q4 2024 earnings?\").close()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from beta.models.serve.engines import VLLMEngine, OpenAIEngineConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "VLLMEngine.__init__() missing 1 required positional argument: 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m mlflow_client \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mset_tracking_uri(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:5000\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m oai_config \u001b[38;5;241m=\u001b[39m OpenAIEngineConfig(data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4096\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m})\n\u001b[0;32m----> 4\u001b[0m vllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mVLLMEngine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moai_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEMPTY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://localhost:8000\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m llm \u001b[38;5;241m=\u001b[39m LLM(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3.1-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine\u001b[38;5;241m=\u001b[39mvllm_engine)\n",
      "\u001b[0;31mTypeError\u001b[0m: VLLMEngine.__init__() missing 1 required positional argument: 'model_name'"
     ]
    }
   ],
   "source": [
    "mlflow_client = mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "oai_config = OpenAIEngineConfig(data={\"temperature\": 0.5, \"max_tokens\": 4096, \"top_p\": 1, \"frequency_penalty\": 0, \"presence_penalty\": 0})\n",
    "vllm_engine = VLLMEngine(config=oai_config, api_key=\"EMPTY\", base_url=\"http://localhost:8000\")\n",
    "\n",
    "\n",
    "llm = LLM(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", engine=vllm_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.models.obj import llm\n",
    "from beta.models.serve.engines import LitServeEngine, OpenAIEngine, OpenRouterEngine, VLLMEngine\n",
    "\n",
    "\n",
    "completion_settings = llm.settings(\n",
    "    temperature=0.5,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    ")\n",
    "\n",
    "# Defaults to OpenRouter\n",
    "# Expects OPENROUTER_API_KEY to be defined in .env\n",
    "gemini_free = llm(\n",
    "    model_name=\"google/gemini-pro-1.5-flash\",\n",
    "    settings=completion_settings,\n",
    ")\n",
    "\n",
    "# If OPENAI_API_KEY, uses { OpenAi | AsyncOpenAI } clients instead of OpenRouter. \n",
    "gpt4o = llm(\n",
    "    model_name=\"openai/o1-mini\",\n",
    "    settings=completion_settings,\n",
    ")\n",
    "\n",
    "# If ANTHROPIC_API_KEY, uses {Anthropic | AsyncAnthopic }\n",
    "sonnet = llm(\n",
    "    model_name=\"anthopic/claude-3.5-sonnet\",\n",
    "    settings = completion_settings,\n",
    ")\n",
    "\n",
    "\n",
    "# Specifying the Engine with OS Model\n",
    "paligemma = llm(\n",
    "    model_name=\"google/paligemma-3b-mix-448\",\n",
    "    engine=LitServeEngine(), \n",
    "    completion_settings=completion_settings\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.tools import CalculatorTool, DataframeTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from beta.agents import BaseAgent, SpeechAgent\n",
    "\n",
    "artifact_df = daft.DataFrame()\n",
    "node_df = daft.DataFrame()\n",
    "document_df = daft.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "earnings = Data.Projects.get(\"Earnings Q4 2024\")\n",
    "knowledge_graph = my_project.Graphs.get(\"latest\")\n",
    "\n",
    "\n",
    "q1_agent = Agent(\n",
    "    llm=paligemma,\n",
    "    tools=[CalculatorTool, DataframeTool],\n",
    "    context=[earnings],\n",
    "    memory={'short':[knowl]},\n",
    "    planning=\n",
    "    rethinking=\n",
    ")\n",
    "\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"{{ question}}\"\"\"\n",
    "\n",
    "@prompt\n",
    "def cot(my_prompt,max_steps):\n",
    "    \"\"\"\n",
    "    System: \n",
    "        Using Chain of Thought:\n",
    "        max_steps = {{max_steps}}\n",
    "\n",
    "        for step in max_steps:\n",
    "            Reason about the request and append, \"Therefore\"\n",
    "        \n",
    "        Make a concluding response \n",
    "\n",
    "    User:\n",
    "    {{ my_prompt }}\n",
    "    \"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from datetime import date\n",
    "\n",
    "class QuarterlyEarnings(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents quarterly earnings data for a company.\n",
    "    \"\"\"\n",
    "    company_name: str = Field(..., description=\"Name of the company\")\n",
    "    fiscal_quarter: int = Field(..., ge=1, le=4, description=\"Fiscal quarter (1-4)\")\n",
    "    fiscal_year: int = Field(..., description=\"Fiscal year\")\n",
    "    revenue: float = Field(..., description=\"Total revenue for the quarter\")\n",
    "    net_income: float = Field(..., description=\"Net income for the quarter\")\n",
    "    earnings_per_share: float = Field(..., description=\"Earnings per share\")\n",
    "    report_date: date = Field(..., description=\"Date of the earnings report\")\n",
    "    analyst_expectations_met: Optional[bool] = Field(None, description=\"Whether analyst expectations were met\")\n",
    "    key_highlights: Optional[List[str]] = Field(None, description=\"Key highlights from the earnings report\")\n",
    "\n",
    "\n",
    "response = await my_agent(\n",
    "    prompt=\n",
    "    response_model=[Address], \n",
    "        reponse_model_strict = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
