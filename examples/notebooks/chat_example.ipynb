{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"/teamspace/studios/this_studio/beta/.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"schema\" in \"SchemaWrapper\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"schema\" in \"Metadata\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    }
   ],
   "source": [
    "from beta import Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed4435b555c4cc4924d1dcee238e7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import json\n",
    "\n",
    "\n",
    "def on_file_selected(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        file_content = change['new']\n",
    "        if not file_content:\n",
    "            print(\"No file selected\")\n",
    "            return\n",
    "        \n",
    "        print(\"File content type:\", type(file_content))\n",
    "        print(\"File content:\", file_content)\n",
    "        \n",
    "        # Handle the tuple structure\n",
    "        if isinstance(file_content, tuple) and len(file_content) > 0:\n",
    "            file_data = file_content[0]\n",
    "            file_name = file_data['name']\n",
    "            \n",
    "            print(f\"Selected file: {file_name}\")\n",
    "            print(\"File data type:\", type(file_data))\n",
    "            \n",
    "            try:\n",
    "                # Create the Artifact\n",
    "                artifact = Artifact(files=[file_name])\n",
    "                print(\"Artifact created successfully\")\n",
    "                print(\"Artifact DataFrame:\")\n",
    "                artifact.df.collect().show()\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating Artifact: {str(e)}\")\n",
    "        else:\n",
    "            print(\"Unexpected file content format\")\n",
    "\n",
    "# Create a file upload widget\n",
    "file_upload = widgets.FileUpload(\n",
    "    accept='',  # Accept all file types\n",
    "    multiple=False  # Allow only single file selection\n",
    ")\n",
    "\n",
    "# Display the file upload widget\n",
    "display(file_upload)\n",
    "\n",
    "# Attach the callback to the file upload widget\n",
    "file_upload.observe(on_file_selected, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-21\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.date(datetime.now())\n",
    "print(str(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    }
   ],
   "source": [
    "artifact_repository = f\"/teamspace/uploads/artifacts/payloads/{str(today)}/\"\n",
    "\n",
    "papers = Artifact(files=[\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2401.05459v2.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2401.18059.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2402.01680v2.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Papers/2402.01968v1.pdf\"\n",
    "], uri_prefix=artifact_repository)\n",
    "\n",
    "br_23_earnings = Artifact(files=[\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 1Q23 Earnings Release.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 2Q23 Earnings Release.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 3Q23 Earnings Release.pdf\",\n",
    "    \"/teamspace/studios/this_studio/beta/examples/data/Blackrock_23_Earnings/BLK 4Q23 Earnings Release.pdf\"\n",
    "], uri_prefix=artifact_repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: PyMicroPartition::to_table, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: PyMicroPartition::to_table, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table class=\"dataframe\">\n",
       "<thead><tr><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">artifact_uri<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">checksum<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">created_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">extension<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">id<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">inserted_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">mime_type<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">name<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">payload<br />Binary</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">size_bytes<br />Int64</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">type<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">updated_at<br />Utf8</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">version<br />Utf8</th></tr></thead>\n",
       "<tbody>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-21//01J8A5PQDZQ3WG9CQB59N9KX9P__BLK 1Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">91f1ec0a9dbc64375b730641fd248101</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T11:33:05.087624</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J8A5PQDZQ3WG9CQB59N9KX9P</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T11:33:05.087624</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 1Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xf1\\xae\\xeef\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1061830</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T11:33:05.087624</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-21//01J8A5PQETY2MYFFVV9QZ3N5HK__BLK 2Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">413cb79dd3084d282a821f61d53c401c</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T11:33:05.114196</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J8A5PQETY2MYFFVV9QZ3N5HK</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T11:33:05.114196</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 2Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xf1\\xae\\xeef\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">316186</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T11:33:05.114196</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-21//01J8A5PQF4HEH4HN5VMGFQ7V7T__BLK 3Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">aea5a59de7f6ebdd8145891af2a0f16c</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T11:33:05.124874</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J8A5PQF4HEH4HN5VMGFQ7V7T</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T11:33:05.124874</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 3Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xf1\\xae\\xeef\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">321016</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T11:33:05.124874</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">/teamspace/uploads/artifacts/payloads/2024-09-21//01J8A5PQFG02KP7PPYWRWCQF71__BLK 4Q23 Earnings Release.pdf.gzip</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">3d6086d1eb1aac9e82b80b86913b751a</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T11:33:05.136292</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">01J8A5PQFG02KP7PPYWRWCQF71</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T11:33:05.136292</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">application/pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">BLK 4Q23 Earnings Release.pdf</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">b\"\\x1f\\x8b\\x08\\x00\\xf1\\xae\\xeef\\x02\\xff\"...</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">316432</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">file</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">2024-09-21T11:33:05.136292</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1.0</div></td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<small>(Showing first 4 of 4 rows)</small>\n",
       "</div>"
      ],
      "text/plain": [
       "╭──────────────────────┬─────────────────────┬─────────────────────┬────────────┬──────┬─────────────────────┬─────────╮\n",
       "│ artifact_uri         ┆ checksum            ┆ created_at          ┆      …     ┆ type ┆ updated_at          ┆ version │\n",
       "│ ---                  ┆ ---                 ┆ ---                 ┆            ┆ ---  ┆ ---                 ┆ ---     │\n",
       "│ Utf8                 ┆ Utf8                ┆ Utf8                ┆ (7 hidden) ┆ Utf8 ┆ Utf8                ┆ Utf8    │\n",
       "╞══════════════════════╪═════════════════════╪═════════════════════╪════════════╪══════╪═════════════════════╪═════════╡\n",
       "│ /teamspace/uploads/a ┆ 91f1ec0a9dbc64375b7 ┆ 2024-09-21T11:33:05 ┆ …          ┆ file ┆ 2024-09-21T11:33:05 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 30641fd248…         ┆ .087624             ┆            ┆      ┆ .087624             ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ /teamspace/uploads/a ┆ 413cb79dd3084d282a8 ┆ 2024-09-21T11:33:05 ┆ …          ┆ file ┆ 2024-09-21T11:33:05 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 21f61d53c4…         ┆ .114196             ┆            ┆      ┆ .114196             ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ /teamspace/uploads/a ┆ aea5a59de7f6ebdd814 ┆ 2024-09-21T11:33:05 ┆ …          ┆ file ┆ 2024-09-21T11:33:05 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 5891af2a0f…         ┆ .124874             ┆            ┆      ┆ .124874             ┆         │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌┤\n",
       "│ /teamspace/uploads/a ┆ 3d6086d1eb1aac9e82b ┆ 2024-09-21T11:33:05 ┆ …          ┆ file ┆ 2024-09-21T11:33:05 ┆ 1.0     │\n",
       "│ rtifacts/…           ┆ 80b86913b7…         ┆ .136292             ┆            ┆      ┆ .136292             ┆         │\n",
       "╰──────────────────────┴─────────────────────┴─────────────────────┴────────────┴──────┴─────────────────────┴─────────╯\n",
       "\n",
       "(Showing first 4 of 4 rows)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.df.collect()\n",
    "br_23_earnings.df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Artifact Persistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 09-21 11:33:05 _custom_ops.py:17] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')\n"
     ]
    }
   ],
   "source": [
    "from beta import Agent\n",
    "from vllm import LLM\n",
    "from beta.tools.obj import CalculatorTool, DataFrameTool\n",
    "from beta.models.serve.engines import VLLMEngine\n",
    "from beta.models.serve.engines import OpenAIEngineConfig\n",
    "from mlflow.client import MlflowClient\n",
    "from daft import DataFrame\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"city\": \"None\",\n",
      "  \"capital\": \"Africa is a continent with 54 countries, each having its own capital. There is no single capital of Africa.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine, OpenAIEngineConfig\n",
    "mlflow.set_experiment(\"Dratos AI\")\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model\", \"gpt-4o\")\n",
    "    mlflow.log_param(\"temperature\", 0.5)\n",
    "    mlflow.log_param(\"max_tokens\", 4096)\n",
    "    mlflow.log_param(\"top_p\", 1)\n",
    "    mlflow.log_param(\"frequency_penalty\", 0)\n",
    "    mlflow.log_param(\"presence_penalty\", 0)\n",
    "    prompt = \"What is the capital of Africa?\"\n",
    "    mlflow.log_param(\"prompt\", prompt)\n",
    "\n",
    "    config = OpenAIEngineConfig(data={\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"top_p\": 1,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    })\n",
    "    engine = OpenAIEngine(config=config)\n",
    "    response = await engine.generate_structured(prompt, structure=\"{city: str, capital: str}\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.prompts import prompt\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"{{ question }}\"\"\"\n",
    "\n",
    "@prompt\n",
    "def cot(my_prompt, max_steps):\n",
    "    \"\"\"\n",
    "    System: \n",
    "        Using Chain of Thought:\n",
    "        max_steps = {{max_steps}}\n",
    "\n",
    "        for step in max_steps:\n",
    "            Reason about the request and append, \"Therefore\"\n",
    "        \n",
    "        Make a concluding response \n",
    "\n",
    "    User:\n",
    "    {{ my_prompt }}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from datetime import date\n",
    "from ray import serve\n",
    "\n",
    "@serve.deployment(name=\"QuarterlyEarningsDeployment\")\n",
    "class QuarterlyEarningsDeployment(BaseModel):\n",
    "    company_name: str = Field(..., description=\"Name of the company\")\n",
    "    fiscal_quarter: int = Field(..., ge=1, le=4, description=\"Fiscal quarter (1-4)\")\n",
    "    fiscal_year: int = Field(..., description=\"Fiscal year\")\n",
    "    revenue: float = Field(..., description=\"Total revenue for the quarter\")\n",
    "    net_income: float = Field(..., description=\"Net income for the quarter\")\n",
    "    earnings_per_share: float = Field(..., description=\"Earnings per share\")\n",
    "    report_date: date = Field(..., description=\"Date of the earnings report\")\n",
    "    analyst_expectations_met: Optional[bool] = Field(None, description=\"Whether analyst expectations were met\")\n",
    "    key_highlights: Optional[List[str]] = Field(None, description=\"Key highlights from the earnings report\")\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return \"QuarterlyEarnings deployment is working\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine\n",
    "\n",
    "def openai_engine_serializer(engine):\n",
    "    # Return the arguments needed to reconstruct the engine\n",
    "    return (engine.model_name, engine.config)\n",
    "\n",
    "def openai_engine_deserializer(model_name, config):\n",
    "    # Reconstruct the engine\n",
    "    return OpenAIEngine(model_name=model_name, config=config)\n",
    "\n",
    "# Register the custom serializer with Ray\n",
    "ray.util.register_serializer(\n",
    "    OpenAIEngine,\n",
    "    serializer=openai_engine_serializer,\n",
    "    deserializer=openai_engine_deserializer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import inspect\n",
    "from pydantic import BaseModel\n",
    "import daft\n",
    "from ray import serve\n",
    "from typing import get_origin, get_args\n",
    "\n",
    "def pydantic_to_daft_schema(model_class):\n",
    "    if isinstance(model_class, serve.Deployment):\n",
    "        # This is a Ray Serve deployment\n",
    "        model_class = model_class.func_or_class\n",
    "\n",
    "    if not inspect.isclass(model_class) or not issubclass(model_class, BaseModel):\n",
    "        raise ValueError(\"Input must be a Pydantic model class or a Ray Serve deployment of a Pydantic model\")\n",
    "\n",
    "    field_dict = {}\n",
    "    for name, field in model_class.model_fields.items():\n",
    "        if field.annotation == str:\n",
    "            field_dict[name] = daft.DataType.string()\n",
    "        elif field.annotation == int:\n",
    "            field_dict[name] = daft.DataType.int64()\n",
    "        elif field.annotation == float:\n",
    "            field_dict[name] = daft.DataType.float64()\n",
    "        elif field.annotation == bool:\n",
    "            field_dict[name] = daft.DataType.boolean()\n",
    "        elif field.annotation == datetime.date:\n",
    "            field_dict[name] = daft.DataType.date()\n",
    "        elif get_origin(field.annotation) == list and get_args(field.annotation)[0] == str:\n",
    "            field_dict[name] = daft.DataType.list(daft.DataType.string())\n",
    "        else:\n",
    "            field_dict[name] = daft.DataType.python()  # Fallback for complex types\n",
    "    return daft.DataType.struct(field_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Deployment.__call__() got an unexpected keyword argument 'company_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 54\u001b[0m\n\u001b[1;32m      8\u001b[0m sample_data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     {\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompany_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mABC Corp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     }\n\u001b[1;32m     51\u001b[0m ]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Convert sample data to QuarterlyEarnings instances\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m quarterly_earnings_instances \u001b[38;5;241m=\u001b[39m [QuarterlyEarningsDeployment(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mitem) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sample_data]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Create a Daft DataFrame from Pydantic models\u001b[39;00m\n\u001b[1;32m     57\u001b[0m revenue_df \u001b[38;5;241m=\u001b[39m daft\u001b[38;5;241m.\u001b[39mfrom_pydantic(QuarterlyEarningsDeployment, quarterly_earnings_instances)\n",
      "Cell \u001b[0;32mIn[15], line 54\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m sample_data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     {\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompany_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mABC Corp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     }\n\u001b[1;32m     51\u001b[0m ]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Convert sample data to QuarterlyEarnings instances\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m quarterly_earnings_instances \u001b[38;5;241m=\u001b[39m [\u001b[43mQuarterlyEarningsDeployment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sample_data]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Create a Daft DataFrame from Pydantic models\u001b[39;00m\n\u001b[1;32m     57\u001b[0m revenue_df \u001b[38;5;241m=\u001b[39m daft\u001b[38;5;241m.\u001b[39mfrom_pydantic(QuarterlyEarningsDeployment, quarterly_earnings_instances)\n",
      "\u001b[0;31mTypeError\u001b[0m: Deployment.__call__() got an unexpected keyword argument 'company_name'"
     ]
    }
   ],
   "source": [
    "# New Cell: Generate Sample Revenue DataFrames\n",
    "\n",
    "from datetime import date\n",
    "from pydantic import BaseModel\n",
    "import daft\n",
    "\n",
    "# Define sample data for Q4 2024\n",
    "sample_data = [\n",
    "    {\n",
    "        \"company_name\": \"ABC Corp\",\n",
    "        \"fiscal_quarter\": 4,\n",
    "        \"fiscal_year\": 2024,\n",
    "        \"revenue\": 500000.0,\n",
    "        \"net_income\": 120000.0,\n",
    "        \"earnings_per_share\": 2.5,\n",
    "        \"report_date\": date(2024, 10, 31),\n",
    "        \"analyst_expectations_met\": True,\n",
    "        \"key_highlights\": [\n",
    "            \"Increased sales in electronics\",\n",
    "            \"Expanded to new markets\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"ABC Corp\",\n",
    "        \"fiscal_quarter\": 4,\n",
    "        \"fiscal_year\": 2024,\n",
    "        \"revenue\": 600000.0,\n",
    "        \"net_income\": 150000.0,\n",
    "        \"earnings_per_share\": 3.0,\n",
    "        \"report_date\": date(2024, 11, 30),\n",
    "        \"analyst_expectations_met\": False,\n",
    "        \"key_highlights\": [\n",
    "            \"Supply chain disruptions\",\n",
    "            \"Higher marketing expenses\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"ABC Corp\",\n",
    "        \"fiscal_quarter\": 4,\n",
    "        \"fiscal_year\": 2024,\n",
    "        \"revenue\": 550000.0,\n",
    "        \"net_income\": 130000.0,\n",
    "        \"earnings_per_share\": 2.8,\n",
    "        \"report_date\": date(2024, 12, 31),\n",
    "        \"analyst_expectations_met\": True,\n",
    "        \"key_highlights\": [\n",
    "            \"Improved operational efficiencies\",\n",
    "            \"New product launch success\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert sample data to QuarterlyEarnings instances\n",
    "quarterly_earnings_instances = [QuarterlyEarningsDeployment(**item) for item in sample_data]\n",
    "\n",
    "# Create a Daft DataFrame from Pydantic models\n",
    "revenue_df = daft.from_pydantic(QuarterlyEarningsDeployment, quarterly_earnings_instances)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Sample Revenue DataFrame:\")\n",
    "revenue_df.collect().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 11:35:59,798\tINFO worker.py:1601 -- Connecting to existing Ray cluster at address: 10.192.12.87:6379...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-21 11:36:04,884 E 3805167 3805167] gcs_rpc_client.h:179: Failed to connect to GCS at address 10.192.12.87:6379 within 5 seconds.\n",
      "[2024-09-21 11:36:35,893 W 3805167 3805167] gcs_client.cc:177: Failed to get cluster ID from GCS server: TimedOut: Timed out while waiting for GCS to become available.\n",
      "[2024-09-21 11:36:41,900 E 3805167 3805167] gcs_rpc_client.h:179: Failed to connect to GCS at address 10.192.12.87:6379 within 5 seconds.\n"
     ]
    }
   ],
   "source": [
    "from daft import Schema\n",
    "import daft\n",
    "import json\n",
    "import ray\n",
    "from ray import serve\n",
    "from beta.agents.agent import Agent, Metadata, SchemaWrapper\n",
    "from beta.tools.obj.calculator_tool import CalculatorTool\n",
    "from beta.tools.obj.dataframe_tool import DataFrameTool\n",
    "from beta.models.serve.engines.openai_engine import OpenAIEngine, OpenAIEngineConfig\n",
    "\n",
    "# Initialize Ray and Serve\n",
    "ray.shutdown()\n",
    "ray.init(address=\"127.0.0.1:6379\", ignore_reinit_error=True)\n",
    "serve.start()\n",
    "\n",
    "# Create OpenAIEngine instances\n",
    "config = OpenAIEngineConfig(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    temperature=0.5,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")  \n",
    "model_engine = OpenAIEngine(model_name=\"gpt-4o\", config=config)\n",
    "embedding_engine = OpenAIEngine(model_name=\"gpt-4o\", config=config)\n",
    "stt_engine = OpenAIEngine(model_name=\"gpt-4o\", config=config)\n",
    "\n",
    "# QuarterlyEarnings as a DataFrame Schema\n",
    "QuarterlyEarningsSchema = pydantic_to_daft_schema(QuarterlyEarningsDeployment)\n",
    "\n",
    "# Create the Agent\n",
    "q1_agent = Agent(\n",
    "    name=\"Q1 Agent\",\n",
    "    model=model_engine,\n",
    "    embedding=embedding_engine,\n",
    "    stt=stt_engine,\n",
    "    tools=[CalculatorTool, DataFrameTool],\n",
    "    metadata=Metadata(schema=SchemaWrapper(schema=QuarterlyEarningsSchema)),\n",
    "    engine=model_engine,\n",
    "    artifacts=[br_23_earnings],\n",
    "    is_async=True,\n",
    ")\n",
    "\n",
    "from beta.prompts import prompt\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"What were the key highlights of the Q4 2024 earnings?\"\"\"\n",
    "\n",
    "response = await q1_agent.process(prompt=my_prompt())\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 24\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    You are an intelligent assistant equipped with Calculator and DataFrame tools.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    {{ question }}\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Initialize the Agent with CalculatorTool and DataFrameTool\u001b[39;00m\n\u001b[1;32m     22\u001b[0m compute_analyze_agent \u001b[38;5;241m=\u001b[39m Agent(\n\u001b[1;32m     23\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputeAnalyzeAgent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 24\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_engine\u001b[49m,          \u001b[38;5;66;03m# Ensure model_engine is defined in your environment\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membedding_engine,  \u001b[38;5;66;03m# Ensure embedding_engine is defined in your environment\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     stt\u001b[38;5;241m=\u001b[39mstt_engine,              \u001b[38;5;66;03m# Ensure stt_engine is defined in your environment\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[CalculatorTool, DataFrameTool],\n\u001b[1;32m     28\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mMetadata(schema\u001b[38;5;241m=\u001b[39mSchemaWrapper(schema\u001b[38;5;241m=\u001b[39mQuarterlyEarningsSchema)),\n\u001b[1;32m     29\u001b[0m     engine\u001b[38;5;241m=\u001b[39mmodel_engine,\n\u001b[1;32m     30\u001b[0m     is_async\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Define the question to be processed\u001b[39;00m\n\u001b[1;32m     34\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculate the total revenue for Q4 2024 and provide a summary of key highlights in a table.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_engine' is not defined"
     ]
    }
   ],
   "source": [
    "# New Cell: Using CalculatorTool and DataFrameTool with Agent\n",
    "\n",
    "from beta.tools import CalculatorTool, DataFrameTool\n",
    "from beta.agents import Agent\n",
    "from beta.prompts import prompt\n",
    "\n",
    "# Define a new prompt that leverages both tools\n",
    "@prompt\n",
    "def compute_and_analyze(question):\n",
    "    \"\"\"\n",
    "    You are an intelligent assistant equipped with Calculator and DataFrame tools.\n",
    "    \n",
    "    Task:\n",
    "    - Calculate the total revenue for Q4 2024.\n",
    "    - Provide a summary of key highlights in a table format.\n",
    "    \n",
    "    User Question:\n",
    "    {{ question }}\n",
    "    \"\"\"\n",
    "\n",
    "# Initialize the Agent with CalculatorTool and DataFrameTool\n",
    "compute_analyze_agent = Agent(\n",
    "    name=\"ComputeAnalyzeAgent\",\n",
    "    model=model_engine,          # Ensure model_engine is defined in your environment\n",
    "    embedding=embedding_engine,  # Ensure embedding_engine is defined in your environment\n",
    "    stt=stt_engine,              # Ensure stt_engine is defined in your environment\n",
    "    tools=[CalculatorTool, DataFrameTool],\n",
    "    metadata=Metadata(schema=SchemaWrapper(schema=QuarterlyEarningsSchema)),\n",
    "    engine=model_engine,\n",
    "    is_async=True\n",
    ")\n",
    "\n",
    "# Define the question to be processed\n",
    "question = \"Calculate the total revenue for Q4 2024 and provide a summary of key highlights in a table.\"\n",
    "\n",
    "# Debugging: Print the constructed prompt before processing\n",
    "constructed_prompt = compute_and_analyze(question)\n",
    "print(\"Constructed Prompt:\")\n",
    "print(constructed_prompt)\n",
    "\n",
    "# Process the prompt with the agent\n",
    "response = await compute_analyze_agent.process(prompt=constructed_prompt)\n",
    "\n",
    "# Display the response\n",
    "print(\"Agent Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from returns.future import Future\n",
    "\n",
    "async def process_agent_response(prompt):\n",
    "    return Future.from_sync(lambda: q1_agent.process(my_prompt(prompt)))\n",
    "\n",
    "response = await process_agent_response(\"What were the key highlights of the Q4 2024 earnings?\").close()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from beta.models.serve.engines import VLLMEngine, OpenAIEngineConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n",
      "INFO:daft_io.stats:IOStatsContext: MicroPartition::concat, Gets: 0, Heads: 0, Lists: 0, BytesRead: 0, AvgGetSize: 0, BytesUploaded: 0, AvgPutSize: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "VLLMEngine.__init__() missing 1 required positional argument: 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m mlflow_client \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mset_tracking_uri(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:5000\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m oai_config \u001b[38;5;241m=\u001b[39m OpenAIEngineConfig(data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4096\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m})\n\u001b[0;32m----> 4\u001b[0m vllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mVLLMEngine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moai_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEMPTY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://localhost:8000\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m llm \u001b[38;5;241m=\u001b[39m LLM(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3.1-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine\u001b[38;5;241m=\u001b[39mvllm_engine)\n",
      "\u001b[0;31mTypeError\u001b[0m: VLLMEngine.__init__() missing 1 required positional argument: 'model_name'"
     ]
    }
   ],
   "source": [
    "mlflow_client = mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "oai_config = OpenAIEngineConfig(data={\"temperature\": 0.5, \"max_tokens\": 4096, \"top_p\": 1, \"frequency_penalty\": 0, \"presence_penalty\": 0})\n",
    "vllm_engine = VLLMEngine(config=oai_config, api_key=\"EMPTY\", base_url=\"http://localhost:8000\")\n",
    "\n",
    "\n",
    "llm = LLM(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", engine=vllm_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.models.obj import llm\n",
    "from beta.models.serve.engines import LitServeEngine, OpenAIEngine, OpenRouterEngine, VLLMEngine\n",
    "\n",
    "\n",
    "completion_settings = llm.settings(\n",
    "    temperature=0.5,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    ")\n",
    "\n",
    "# Defaults to OpenRouter\n",
    "# Expects OPENROUTER_API_KEY to be defined in .env\n",
    "gemini_free = llm(\n",
    "    model_name=\"google/gemini-pro-1.5-flash\",\n",
    "    settings=completion_settings,\n",
    ")\n",
    "\n",
    "# If OPENAI_API_KEY, uses { OpenAi | AsyncOpenAI } clients instead of OpenRouter. \n",
    "gpt4o = llm(\n",
    "    model_name=\"openai/o1-mini\",\n",
    "    settings=completion_settings,\n",
    ")\n",
    "\n",
    "# If ANTHROPIC_API_KEY, uses {Anthropic | AsyncAnthopic }\n",
    "sonnet = llm(\n",
    "    model_name=\"anthopic/claude-3.5-sonnet\",\n",
    "    settings = completion_settings,\n",
    ")\n",
    "\n",
    "\n",
    "# Specifying the Engine with OS Model\n",
    "paligemma = llm(\n",
    "    model_name=\"google/paligemma-3b-mix-448\",\n",
    "    engine=LitServeEngine(), \n",
    "    completion_settings=completion_settings\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta.tools import CalculatorTool, DataframeTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from beta.agents import BaseAgent, SpeechAgent\n",
    "\n",
    "artifact_df = daft.DataFrame()\n",
    "node_df = daft.DataFrame()\n",
    "document_df = daft.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "earnings = Data.Projects.get(\"Earnings Q4 2024\")\n",
    "knowledge_graph = my_project.Graphs.get(\"latest\")\n",
    "\n",
    "\n",
    "q1_agent = Agent(\n",
    "    llm=paligemma,\n",
    "    tools=[CalculatorTool, DataframeTool],\n",
    "    context=[earnings],\n",
    "    memory={'short':[knowl]},\n",
    "    planning=\n",
    "    rethinking=\n",
    ")\n",
    "\n",
    "\n",
    "@prompt\n",
    "def my_prompt(question):\n",
    "    \"\"\"{{ question}}\"\"\"\n",
    "\n",
    "@prompt\n",
    "def cot(my_prompt,max_steps):\n",
    "    \"\"\"\n",
    "    System: \n",
    "        Using Chain of Thought:\n",
    "        max_steps = {{max_steps}}\n",
    "\n",
    "        for step in max_steps:\n",
    "            Reason about the request and append, \"Therefore\"\n",
    "        \n",
    "        Make a concluding response \n",
    "\n",
    "    User:\n",
    "    {{ my_prompt }}\n",
    "    \"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from datetime import date\n",
    "\n",
    "class QuarterlyEarnings(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents quarterly earnings data for a company.\n",
    "    \"\"\"\n",
    "    company_name: str = Field(..., description=\"Name of the company\")\n",
    "    fiscal_quarter: int = Field(..., ge=1, le=4, description=\"Fiscal quarter (1-4)\")\n",
    "    fiscal_year: int = Field(..., description=\"Fiscal year\")\n",
    "    revenue: float = Field(..., description=\"Total revenue for the quarter\")\n",
    "    net_income: float = Field(..., description=\"Net income for the quarter\")\n",
    "    earnings_per_share: float = Field(..., description=\"Earnings per share\")\n",
    "    report_date: date = Field(..., description=\"Date of the earnings report\")\n",
    "    analyst_expectations_met: Optional[bool] = Field(None, description=\"Whether analyst expectations were met\")\n",
    "    key_highlights: Optional[List[str]] = Field(None, description=\"Key highlights from the earnings report\")\n",
    "\n",
    "\n",
    "response = await my_agent(\n",
    "    prompt=\n",
    "    response_model=[Address], \n",
    "        reponse_model_strict = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
