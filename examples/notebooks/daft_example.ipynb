{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lancedb in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (0.13.0)\n",
      "Requirement already satisfied: getdaft in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (0.3.3)\n",
      "Requirement already satisfied: pyarrow in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (14.0.2)\n",
      "Requirement already satisfied: deprecation in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from lancedb) (2.1.0)\n",
      "Requirement already satisfied: pylance==0.17.0 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from lancedb) (0.17.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from lancedb) (2.32.3)\n",
      "Requirement already satisfied: retry>=0.9.2 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from lancedb) (0.9.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from lancedb) (4.66.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from lancedb) (2.9.2)\n",
      "Requirement already satisfied: attrs>=21.3.0 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from lancedb) (24.2.0)\n",
      "Requirement already satisfied: packaging in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from lancedb) (24.1)\n",
      "Requirement already satisfied: cachetools in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from lancedb) (5.5.0)\n",
      "Requirement already satisfied: overrides>=0.7 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from lancedb) (7.7.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from pylance==0.17.0->lancedb) (1.26.4)\n",
      "Requirement already satisfied: fsspec in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from getdaft) (2024.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from pydantic>=1.10->lancedb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from pydantic>=1.10->lancedb) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from pydantic>=1.10->lancedb) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from requests>=2.31.0->lancedb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from requests>=2.31.0->lancedb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from requests>=2.31.0->lancedb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from requests>=2.31.0->lancedb) (2024.8.30)\n",
      "Requirement already satisfied: decorator>=3.4.2 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from retry>=0.9.2->lancedb) (5.1.1)\n",
      "Requirement already satisfied: py<2.0.0,>=1.4.26 in /Users/nicolasnahas/Documents/PROJETS/DRATOS/DEV/beta/venv/lib/python3.11/site-packages (from retry>=0.9.2->lancedb) (1.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lancedb getdaft pyarrow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyarrow as pa\n",
    "import gzip\n",
    "import hashlib\n",
    "import mimetypes\n",
    "from ulid import ULID\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from typing import Optional, Dict, Any, List\n",
    "import os\n",
    "import json\n",
    "import lancedb\n",
    "import daft\n",
    "from daft import lit, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_schema = [\n",
    "    pa.field(\n",
    "        \"id\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"ULID Unique identifier for the record\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"type\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Type of the data object\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"created_at\",\n",
    "        pa.timestamp(\"ns\", tz=\"UTC\"),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Timestamp when the record was created\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"updated_at\",\n",
    "        pa.timestamp(\"ns\", tz=\"UTC\"),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Timestamp when the record was last updated\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"inserted_at\",\n",
    "        pa.timestamp(\"ns\", tz=\"UTC\"),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Timestamp when the data object was inserted into the database\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "artifact_schema = [\n",
    "    pa.field(\n",
    "        \"name\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Name of the artifact\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"artifact_uri\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"URI where the artifact is stored\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"payload\",\n",
    "        pa.binary(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Gzipped binary of the artifact file's contents\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"extension\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"File extension of the artifact\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"mime_type\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"MIME type of the artifact\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"version\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Version of the artifact\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"size_bytes\",\n",
    "        pa.int64(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Size of the artifact in bytes\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"checksum\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"MD5 checksum of the artifact\"},\n",
    "    ),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import ClassVar\n",
    "\n",
    "class Artifact:\n",
    "    \"\"\"\n",
    "    Versatile model for managing artifacts in a data system.\n",
    "    \"\"\"\n",
    "\n",
    "    schema: ClassVar[pa.Schema] = pa.schema(base_schema + artifact_schema)\n",
    "    obj_type: ClassVar[str] = \"Artifact\"\n",
    "\n",
    "    def __init__(self, files: List[str] = None, uri_prefix: Optional[str] = None):\n",
    "        # Create an empty DataFrame with the schema from ArtifactObject\n",
    "        empty_data = {field.name: [] for field in self.schema}\n",
    "        self.df = daft.from_pydict(empty_data)\n",
    "\n",
    "        if files:\n",
    "            self._populate_from_local_file(files, uri_prefix)\n",
    "\n",
    "    def _populate_from_local_file(self, files: List[str], uri_prefix: Optional[str] = None):\n",
    "        rows = []\n",
    "        for file in files:\n",
    "            with open(file, \"rb\") as f:\n",
    "                content = f.read()  \n",
    "\n",
    "            file_id = str(ULID())\n",
    "            now = datetime.now().isoformat()\n",
    "            file_name = os.path.basename(file)\n",
    "            artifact_uri = f\"{uri_prefix}/{file_id}__{file_name}.gzip\"\n",
    "            payload = gzip.compress(content)\n",
    "            extension = file_name.split(\".\")[1]\n",
    "            mime_type = mimetypes.guess_type(file)[0] or \"application/octet-stream\"\n",
    "            branch = \"1.0\"\n",
    "            size_bytes = len(content)\n",
    "            checksum = hashlib.md5(payload).hexdigest()\n",
    "            \n",
    "            self.df = self.df.with_column(\"id\", slit(file_id)) \\\n",
    "                .with_column(\"created_at\", now) \\\n",
    "                .with_column(\"updated_at\", now) \\\n",
    "                .with_column(\"inserted_at\", now) \\\n",
    "                .with_column(\"name\", file_name) \\\n",
    "                .with_column(\"artifact_uri\", artifact_uri) \\\n",
    "                .with_column(\"payload\", payload) \\\n",
    "                .with_column(\"extension\", extension) \\\n",
    "                .with_column(\"mime_type\", mime_type) \\\n",
    "                .with_column(\"version\", \"1.0\") \\\n",
    "                .with_column(\"size_bytes\", size_bytes) \\\n",
    "                .with_column(\"checksum\", checksum)  \n",
    "\n",
    "        self.df = daft.from_pylist(rows)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<Artifact with {len(self.df)} files>\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataType.struct() takes 2 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdaft\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdaft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataType, Schema, DataFrame, col \n\u001b[1;32m      7\u001b[0m multimodal_data_schema \u001b[38;5;241m=\u001b[39m Schema({\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mDataType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstruct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mDataType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# text\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mDataType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# image\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mDataType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# audio\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mDataType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# video\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mDataType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mns\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# timestamp\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     15\u001b[0m })\n\u001b[1;32m     17\u001b[0m metadata_schema \u001b[38;5;241m=\u001b[39m Schema({\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: DataType\u001b[38;5;241m.\u001b[39mstring(),\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: DataType\u001b[38;5;241m.\u001b[39mstring(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m })\n\u001b[1;32m     31\u001b[0m embeddings_schema \u001b[38;5;241m=\u001b[39m Schema({\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: DataType\u001b[38;5;241m.\u001b[39membedding(),\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata_schema,\n\u001b[1;32m     34\u001b[0m })\n",
      "\u001b[0;31mTypeError\u001b[0m: DataType.struct() takes 2 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "from daft import DataType, Schema, DataFrame, TimeUnit, col\n",
    "import daft\n",
    "\n",
    "from daft import DataType, Schema, DataFrame, col \n",
    "\n",
    "\n",
    "multimodal_data_schema = Schema({\n",
    "    \"data\": DataType.struct(\n",
    "        DataType.string(), # text\n",
    "        DataType.image(), # image\n",
    "        DataType.string(), # audio\n",
    "        DataType.string(), # video\n",
    "        DataType.timestamp('ns'), # timestamp\n",
    "    ),\n",
    "})\n",
    "\n",
    "metadata_schema = Schema({\n",
    "    \"id\": DataType.string(),\n",
    "    \"name\": DataType.string(),\n",
    "    \"description\": DataType.string(),\n",
    "    \"created_at\": DataType.timestamp('ns'),\n",
    "    \"updated_at\": DataType.timestamp('ns'),\n",
    "    \"inserted_at\": DataType.timestamp('ns'),\n",
    "    \"version\": DataType.string(),\n",
    "    \"size_bytes\": DataType.uint64(),\n",
    "    \"checksum\": DataType.string(),\n",
    "    \"mime_type\": DataType.string(),\n",
    "\n",
    "})\n",
    "\n",
    "embeddings_schema = Schema({\n",
    "    \"embeddings\": DataType.embedding(),\n",
    "    \"embedding_metadata\": metadata_schema,\n",
    "})\n",
    "\n",
    "base_schema = Schema({\n",
    "    \"data\": multimodal_data_schema,\n",
    "    \"metadata\": metadata_schema,\n",
    "    \"embeddings\": DataType.embedding(),\n",
    "    \"embedding_metadata\": metadata_schema,\n",
    "\n",
    "})\n",
    "\n",
    "metadata_df = DataFrame(\n",
    "    data=None,\n",
    "    schema=metadata_schema,\n",
    "    partition_by=[\"id\"],\n",
    "    mode=\"append\",\n",
    "    name=\"metadata\",\n",
    ")\n",
    "\n",
    "DataType.struct(\n",
    "        DataType.string(), # id\n",
    "        DataType.string(), # name\n",
    "        DataType.string(), # description\n",
    "        DataType.timestamp('ns'), # created_at\n",
    "        DataType.timestamp('ns'), # updated_at\n",
    "        DataType.timestamp('ns'), # inserted_at\n",
    "        DataType.string(), # version\n",
    "        DataType.uint64(), # size_bytes\n",
    "        DataType.string(), # checksum\n",
    "        DataType.string(), # mime_type\n",
    "    ),\n",
    "\n",
    "image_schema = Schema({\n",
    "    \"\": DataType.string(),\n",
    "    \"width\": DataType.uint64(),\n",
    "    \"height\": DataType.uint64(),\n",
    "})\n",
    "\n",
    "# Base Node Schema\n",
    "base_node_schema = Schema({\n",
    "    \"content\": DataType.struct(\n",
    "        DataType.string(), # text\n",
    "        DataType.image(), # image\n",
    "        DataType.string(), # audio\n",
    "        DataType.string(), # video\n",
    "        DataType.timestamp('ns'), # timestamp\n",
    "    ),\n",
    "    \"type\": DataType.string(),\n",
    "    \"url\": DataType.string(),\n",
    "    \"timestamp\": DataType.timestamp('ns'),\n",
    "    \"metadata\": DataType.struct(\n",
    "        DataType.string(), # id\n",
    "        DataType.string(), # name\n",
    "        DataType.string(), # description\n",
    "        DataType.timestamp('ns'), # created_at\n",
    "        DataType.timestamp('ns'), # updated_at\n",
    "        DataType.timestamp('ns'), # inserted_at\n",
    "        DataType.string(), # version\n",
    "    )\n",
    "})\n",
    "\n",
    "# Edge Schema\n",
    "edge_schema = Schema({\n",
    "    \"source\": DataType.string(),\n",
    "    \"target\": DataType.string(),\n",
    "    \"relation\": DataType.string(),\n",
    "    \"timestamp\": DataType.timestamp('ns'),\n",
    "    \"metadata\": DataType.struct(\n",
    "        DataType.string(), # id\n",
    "        DataType.string(), # name\n",
    "        DataType.string(), # description\n",
    "        DataType.timestamp('ns'), # created_at\n",
    "        DataType.timestamp('ns'), # updated_at\n",
    "        DataType.timestamp('ns'), # inserted_at\n",
    "        DataType.string(), # version\n",
    "    )\n",
    "})\n",
    "\n",
    "class BaseStructure:\n",
    "    def __init__(self, index: str):\n",
    "        self.index = index\n",
    "        self.nodes = DataFrame(schema=base_node_schema)\n",
    "\n",
    "    def add_node(self, nodes: DataFrame):\n",
    "        new_node = DataFrame.from_pydict(nodes)\n",
    "        self.nodes = self.nodes.concat(new_node)\n",
    "        return self\n",
    "\n",
    "    def get(self, ):\n",
    "        return self.nodes.collect()\n",
    "\n",
    "    def filter(self, condition):\n",
    "        \"\"\"\n",
    "        Filter the nodes DataFrame.\n",
    "\n",
    "        Args:\n",
    "            condition (str): A condition to filter the nodes.\n",
    "        \"\"\"\n",
    "        self.nodes = self.nodes.filter(condition)\n",
    "        return self\n",
    "\n",
    "    def upsert(self, nodes: DataFrame):\n",
    "        \"\"\"\n",
    "        Upsert a node into the nodes DataFrame.\n",
    "\n",
    "        Args:\n",
    "            nodes (DataFrame): A DataFrame of nodes to upsert.\n",
    "        \"\"\"\n",
    "        condition = self.nodes.select(\"metadata.id\") == nodes.select(\"metadata.id\")\n",
    "        self.nodes = self.nodes.filter(nodes, condition)\n",
    "        return self\n",
    "                                                \n",
    "    def sql(self, query: str):\n",
    "        return self.nodes.sql(query)\n",
    "\n",
    "class EdgeStructure:\n",
    "    def __init__(self, index: str):\n",
    "        self.index = index\n",
    "        self.edges = DataFrame(schema=edge_schema)\n",
    "\n",
    "    def add_edge(self, edge_data: dict):\n",
    "        new_edge = DataFrame.from_pydict(edge_data)\n",
    "        self.edges = self.edges.concat(new_edge)\n",
    "        return self\n",
    "    \n",
    "    def get_edges(self):\n",
    "        return self.edges\n",
    "\n",
    "    def filter_edges(self, condition):\n",
    "        self.edges = self.edges.filter(condition)\n",
    "        return self\n",
    "\n",
    "    def upsert_edges(self, source: str, target: str, update_dict: dict):\n",
    "        condition = \"\"\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, index: str):\n",
    "        self.base = BaseStructure(index)\n",
    "\n",
    "    def add_text(self, id: str, content: str):\n",
    "        return self.base.add_node({\"id\": id, \"content\": content, \"type\": \"text\"})\n",
    "\n",
    "    def add_image(self, id: str, content: str, url: str):\n",
    "        return self.base.add_node({\"id\": id, \"content\": content, \"type\": \"image\", \"url\": url})\n",
    "\n",
    "    def add_audio(self, id: str, content: str, url: str, duration: float):\n",
    "        return self.base.add_node({\"id\": id, \"content\": content, \"type\": \"audio\", \"url\": url, \"duration\": duration})\n",
    "\n",
    "    def add_video(self, id: str, content: str, url: str, duration: float):\n",
    "        return self.base.add_node({\"id\": id, \"content\": content, \"type\": \"video\", \"url\": url, \"duration\": duration})\n",
    "\n",
    "    def add_timestamp(self, id: str, content: str, timestamp):\n",
    "        return self.base.add_node({\"id\": id, \"content\": content, \"type\": \"timestamp\", \"timestamp\": timestamp})\n",
    "\n",
    "    def get_nodes(self):\n",
    "        return self.base.get_nodes()\n",
    "\n",
    "    def filter_nodes(self, condition):\n",
    "        self.base.filter_nodes(condition)\n",
    "        return self\n",
    "\n",
    "    def update_node(self, node_id: str, update_dict: dict):\n",
    "        self.base.update_node(node_id, update_dict)\n",
    "        return self\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, index: str):\n",
    "        self.base = BaseStructure(index)\n",
    "        self.edges = DataFrame(schema=edge_schema)\n",
    "\n",
    "    def add_node(self, node_data: dict):\n",
    "        self.base.add_node(node_data)\n",
    "        return self\n",
    "\n",
    "    def add_edge(self, edge_data: dict):\n",
    "        new_edge = DataFrame.from_pydict(edge_data)\n",
    "        self.edges = self.edges.concat(new_edge)\n",
    "        return self\n",
    "\n",
    "    def get_nodes(self):\n",
    "        return self.base.get_nodes()\n",
    "\n",
    "    def get_edges(self):\n",
    "        return self.edges\n",
    "\n",
    "    def filter_nodes(self, condition):\n",
    "        self.base.filter_nodes(condition)\n",
    "        return self\n",
    "\n",
    "    def filter_edges(self, condition):\n",
    "        self.edges = self.edges.filter(condition)\n",
    "        return self\n",
    "\n",
    "    def update_node(self, node_id: str, update_dict: dict):\n",
    "        self.base.update_node(node_id, update_dict)\n",
    "        return self\n",
    "\n",
    "    def update_edge(self, source: str, target: str, update_dict: dict):\n",
    "        condition = (self.edges[\"source\"] == source) & (self.edges[\"target\"] == target)\n",
    "        for key, value in update_dict.items():\n",
    "            self.edges = self.edges.with_column(key, \n",
    "                daft.where(condition, daft.lit(value), self.edges[key]))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and populate a document\n",
    "doc = (Document(\"doc1\")\n",
    "    .add_text(\"1\", \"This is a document\")\n",
    "    .add_image(\"2\", \"An image in the document\", \"http://example.com/image.jpg\")\n",
    "    .add_audio(\"3\", \"An audio clip\", \"http://example.com/audio.mp3\", 120.5)\n",
    "    .filter_nodes(col(\"type\") != \"audio\"))\n",
    "\n",
    "# Create and populate a graph\n",
    "graph = (Graph(\"graph1\")\n",
    "    .add_node({\"id\": \"1\", \"content\": \"Hello, world!\", \"type\": \"text\"})\n",
    "    .add_node({\"id\": \"2\", \"content\": \"A beautiful landscape\", \"type\": \"image\", \"url\": \"http://example.com/image.jpg\"})\n",
    "    .add_edge({\"source\": \"1\", \"target\": \"2\", \"relation\": \"describes\"})\n",
    "    .update_node(\"1\", {\"content\": \"Updated content\"})\n",
    "    .filter_edges(col(\"relation\") == \"describes\"))\n",
    "\n",
    "# Get nodes and edges\n",
    "doc_nodes = doc.get_nodes()\n",
    "graph_nodes = graph.get_nodes()\n",
    "graph_edges = graph.get_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Task Network,:\n",
    "class HTN():\n",
    "    def __init__(self, index):\n",
    "        self.graph = Graph(index)\n",
    "\n",
    "    def add_node(self, node_data: dict):\n",
    "        new_node = DataFrame.from_pydict(node_data)\n",
    "        self.nodes = self.nodes.concat(new_node)\n",
    "        return self\n",
    "\n",
    "    def add_edge(self, edge_data: dict):\n",
    "        new_edge = DataFrame.from_pydict(edge_data)\n",
    "        self.edges = self.edges.concat(new_edge)\n",
    "        return self\n",
    "\n",
    "    def get_nodes(self):\n",
    "        return self.nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
