{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lancedb getdaft pyarrow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyarrow as pa\n",
    "import gzip\n",
    "import hashlib\n",
    "import mimetypes\n",
    "from ulid import ULID\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from typing import Optional, Dict, Any, List\n",
    "import os\n",
    "import json\n",
    "import lancedb\n",
    "import daft\n",
    "from daft import lit, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_schema = [\n",
    "    pa.field(\n",
    "        \"id\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        primary_key=True,\n",
    "        metadata={\"description\": \"ULID Unique identifier for the record\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"type\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Type of the data object\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"created_at\",\n",
    "        pa.timestamp(\"ns\", tz=\"UTC\"),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Timestamp when the record was created\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"updated_at\",\n",
    "        pa.timestamp(\"ns\", tz=\"UTC\"),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Timestamp when the record was last updated\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"inserted_at\",\n",
    "        pa.timestamp(\"ns\", tz=\"UTC\"),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Timestamp when the data object was inserted into the database\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "artifact_schema = [\n",
    "    pa.field(\n",
    "        \"name\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Name of the artifact\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"artifact_uri\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"URI where the artifact is stored\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"payload\",\n",
    "        pa.binary(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Gzipped binary of the artifact file's contents\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"extension\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"File extension of the artifact\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"mime_type\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"MIME type of the artifact\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"version\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Version of the artifact\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"size_bytes\",\n",
    "        pa.int64(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"Size of the artifact in bytes\"},\n",
    "    ),\n",
    "    pa.field(\n",
    "        \"checksum\",\n",
    "        pa.string(),\n",
    "        nullable=False,\n",
    "        metadata={\"description\": \"MD5 checksum of the artifact\"},\n",
    "    ),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 2.7.-1' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/commands/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "class Artifact:\n",
    "    \"\"\"\n",
    "    Versatile model for managing artifacts in a data system.\n",
    "    \"\"\"\n",
    "\n",
    "    schema: ClassVar[pa.Schema] = pa.schema(base_schema + artifact_schema)\n",
    "    obj_type: ClassVar[str] = \"Artifact\"\n",
    "\n",
    "    def __init__(self, files: List[str] = None, uri_prefix: Optional[str] = None):\n",
    "        # Create an empty DataFrame with the schema from ArtifactObject\n",
    "        empty_data = {field.name: [] for field in self.schema}\n",
    "        self.df = daft.from_pydict(empty_data)\n",
    "\n",
    "        if files:\n",
    "            self._populate_from_local_file(files, uri_prefix)\n",
    "\n",
    "    def _populate_from_local_file(self, files: List[str], uri_prefix: Optional[str] = None):\n",
    "        rows = []\n",
    "        for file in files:\n",
    "            with open(file, \"rb\") as f:\n",
    "                content = f.read()  \n",
    "\n",
    "            file_id = str(ULID())\n",
    "            now = datetime.now().isoformat()\n",
    "            file_name = os.path.basename(file)\n",
    "            artifact_uri = f\"{uri_prefix}/{file_id}__{file_name}.gzip\"\n",
    "            payload = gzip.compress(content)\n",
    "            extension = file_name.split(\".\")[1]\n",
    "            mime_type = mimetypes.guess_type(file)[0] or \"application/octet-stream\"\n",
    "            branch = \"1.0\"\n",
    "            size_bytes = len(content)\n",
    "            checksum = hashlib.md5(payload).hexdigest()\n",
    "            \n",
    "            self.df = self.df.with_column(\"id\", slit(file_id)) \\\n",
    "                .with_column(\"created_at\", now) \\\n",
    "                .with_column(\"updated_at\", now) \\\n",
    "                .with_column(\"inserted_at\", now) \\\n",
    "                .with_column(\"name\", file_name) \\\n",
    "                .with_column(\"artifact_uri\", artifact_uri) \\\n",
    "                .with_column(\"payload\", payload) \\\n",
    "                .with_column(\"extension\", extension) \\\n",
    "                .with_column(\"mime_type\", mime_type) \\\n",
    "                .with_column(\"version\", \"1.0\") \\\n",
    "                .with_column(\"size_bytes\", size_bytes) \\\n",
    "                .with_column(\"checksum\", checksum)  \n",
    "\n",
    "        self.df = daft.from_pylist(rows)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<Artifact with {len(self.df)} files>\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from daft import DataType, Schema, DataFrame, TimeUnit, col\n",
    "import daft\n",
    "\n",
    "from daft import DataType, Schema, DataFrame, col \n",
    "\n",
    "\n",
    "multimodal_data_schema = Schema({\n",
    "    \"data\": DataType.struct(\n",
    "        DataType.string(), # text\n",
    "        DataType.image(), # image\n",
    "        DataType.string(), # audio\n",
    "        DataType.string(), # video\n",
    "        DataType.timestamp('ns'), # timestamp\n",
    "    ),\n",
    "})\n",
    "\n",
    "metadata_schema = Schema({\n",
    "    \"id\": DataType.string(),\n",
    "    \"name\": DataType.string(),\n",
    "    \"description\": DataType.string(),\n",
    "    \"created_at\": DataType.timestamp('ns'),\n",
    "    \"updated_at\": DataType.timestamp('ns'),\n",
    "    \"inserted_at\": DataType.timestamp('ns'),\n",
    "    \"version\": DataType.string(),\n",
    "    \"size_bytes\": DataType.uint64(),\n",
    "    \"checksum\": DataType.string(),\n",
    "    \"mime_type\": DataType.string(),\n",
    "\n",
    "})\n",
    "\n",
    "embeddings_schema = Schema({\n",
    "    \"embeddings\": DataType.embedding(),\n",
    "    \"embedding_metadata\": metadata_schema,\n",
    "})\n",
    "\n",
    "base_schema = Schema({\n",
    "    \"data\": \n",
    "    \"metadata\": metadata_schema,\n",
    "    \"embeddings\": DataType.embedding(),\n",
    "    \"embedding_metadata\": metadata_schema,\n",
    "\n",
    "})\n",
    "\n",
    "metadata_df = DataFrame(\n",
    "    data=None,\n",
    "    schema=metadata_schema,\n",
    "    partition_by=[\"id\"],\n",
    "    mode=\"append\",\n",
    "    name=\"metadata\",\n",
    ")\n",
    "\n",
    "DataType.struct(\n",
    "        DataType.string(), # id\n",
    "        DataType.string(), # name\n",
    "        DataType.string(), # description\n",
    "        DataType.timestamp('ns'), # created_at\n",
    "        DataType.timestamp('ns'), # updated_at\n",
    "        DataType.timestamp('ns'), # inserted_at\n",
    "        DataType.string(), # version\n",
    "        DataType.uint64(), # size_bytes\n",
    "        DataType.string(), # checksum\n",
    "        DataType.string(), # mime_type\n",
    "    ),\n",
    "\n",
    "image_schema = Schema({\n",
    "    \"\": DataType.string(),\n",
    "    \"width\": DataType.uint64(),\n",
    "    \"height\": DataType.uint64(),\n",
    "})\n",
    "\n",
    "# Base Node Schema\n",
    "base_node_schema = Schema({\n",
    "    \"content\": DataType.struct(\n",
    "        DataType.string(), # text\n",
    "        DataType.image(), # image\n",
    "        DataType.string(), # audio\n",
    "        DataType.string(), # video\n",
    "        DataType.timestamp('ns'), # timestamp\n",
    "    ),\n",
    "    \"type\": DataType.string(),\n",
    "    \"url\": DataType.string(),\n",
    "    \"timestamp\": DataType.timestamp('ns'),\n",
    "    \"metadata\": DataType.struct(\n",
    "        DataType.string(), # id\n",
    "        DataType.string(), # name\n",
    "        DataType.string(), # description\n",
    "        DataType.timestamp('ns'), # created_at\n",
    "        DataType.timestamp('ns'), # updated_at\n",
    "        DataType.timestamp('ns'), # inserted_at\n",
    "        DataType.string(), # version\n",
    "    )\n",
    "})\n",
    "\n",
    "# Edge Schema\n",
    "edge_schema = Schema({\n",
    "    \"source\": DataType.string(),\n",
    "    \"target\": DataType.string(),\n",
    "    \"relation\": DataType.string(),\n",
    "    \"timestamp\": DataType.timestamp('ns'),\n",
    "    \"metadata\": DataType.struct(\n",
    "        DataType.string(), # id\n",
    "        DataType.string(), # name\n",
    "        DataType.string(), # description\n",
    "        DataType.timestamp('ns'), # created_at\n",
    "        DataType.timestamp('ns'), # updated_at\n",
    "        DataType.timestamp('ns'), # inserted_at\n",
    "        DataType.string(), # version\n",
    "    )\n",
    "})\n",
    "\n",
    "class BaseStructure:\n",
    "    def __init__(self, index: str):\n",
    "        self.index = index\n",
    "        self.nodes = DataFrame(schema=base_node_schema)\n",
    "\n",
    "    def add_node(self, nodes: DataFrame):\n",
    "        new_node = DataFrame.from_pydict(node_data)\n",
    "        self.nodes = self.nodes.concat(new_node)\n",
    "        return self\n",
    "\n",
    "    def get(self, ):\n",
    "        return self.nodes.collect()\n",
    "\n",
    "    def filter(self, condition):\n",
    "        \"\"\"\n",
    "        Filter the nodes DataFrame.\n",
    "\n",
    "        Args:\n",
    "            condition (str): A condition to filter the nodes.\n",
    "        \"\"\"\n",
    "        self.nodes = self.nodes.filter(condition)\n",
    "        return self\n",
    "\n",
    "    def upsert(self, nodes: DataFrame):\n",
    "        \"\"\"\n",
    "        Upsert a node into the nodes DataFrame.\n",
    "\n",
    "        Args:\n",
    "            nodes (DataFrame): A DataFrame of nodes to upsert.\n",
    "        \"\"\"\n",
    "        condition = self.nodes.select(\"metadata.id\") == nodes.select(\"metadata.id\")\n",
    "        self.nodes = self.nodes.filter(nodes, condition)\n",
    "        return self\n",
    "                                                \n",
    "    def sql(self, query: str):\n",
    "        return self.nodes.sql(query)\n",
    "\n",
    "class EdgeStructure:\n",
    "    def __init__(self, index: str):\n",
    "        self.index = index\n",
    "        self.edges = DataFrame(schema=edge_schema)\n",
    "\n",
    "    def add_edge(self, edge_data: dict):\n",
    "        new_edge = DataFrame.from_pydict(edge_data)\n",
    "        self.edges = self.edges.concat(new_edge)\n",
    "        return self\n",
    "    \n",
    "    def get_edges(self):\n",
    "        return self.edges\n",
    "\n",
    "    def filter_edges(self, condition):\n",
    "        self.edges = self.edges.filter(condition)\n",
    "        return self\n",
    "\n",
    "    def upsert_edges(self, source: str, target: str, update_dict: dict):\n",
    "        condition = \n",
    "\n",
    "class Document:\n",
    "    def __init__(self, index: str):\n",
    "        self.base = BaseStructure(index)\n",
    "\n",
    "    def add_text(self, id: str, content: str):\n",
    "        return self.base.add_node({\"id\": id, \"content\": content, \"type\": \"text\"})\n",
    "\n",
    "    def add_image(self, id: str, content: str, url: str):\n",
    "        return self.base.add_node({\"id\": id, \"content\": content, \"type\": \"image\", \"url\": url})\n",
    "\n",
    "    def add_audio(self, id: str, content: str, url: str, duration: float):\n",
    "        return self.base.add_node({\"id\": id, \"content\": content, \"type\": \"audio\", \"url\": url, \"duration\": duration})\n",
    "\n",
    "    def add_video(self, id: str, content: str, url: str, duration: float):\n",
    "        return self.base.add_node({\"id\": id, \"content\": content, \"type\": \"video\", \"url\": url, \"duration\": duration})\n",
    "\n",
    "    def add_timestamp(self, id: str, content: str, timestamp):\n",
    "        return self.base.add_node({\"id\": id, \"content\": content, \"type\": \"timestamp\", \"timestamp\": timestamp})\n",
    "\n",
    "    def get_nodes(self):\n",
    "        return self.base.get_nodes()\n",
    "\n",
    "    def filter_nodes(self, condition):\n",
    "        self.base.filter_nodes(condition)\n",
    "        return self\n",
    "\n",
    "    def update_node(self, node_id: str, update_dict: dict):\n",
    "        self.base.update_node(node_id, update_dict)\n",
    "        return self\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, index: str):\n",
    "        self.base = BaseStructure(index)\n",
    "        self.edges = DataFrame(schema=edge_schema)\n",
    "\n",
    "    def add_node(self, node_data: dict):\n",
    "        self.base.add_node(node_data)\n",
    "        return self\n",
    "\n",
    "    def add_edge(self, edge_data: dict):\n",
    "        new_edge = DataFrame.from_pydict(edge_data)\n",
    "        self.edges = self.edges.concat(new_edge)\n",
    "        return self\n",
    "\n",
    "    def get_nodes(self):\n",
    "        return self.base.get_nodes()\n",
    "\n",
    "    def get_edges(self):\n",
    "        return self.edges\n",
    "\n",
    "    def filter_nodes(self, condition):\n",
    "        self.base.filter_nodes(condition)\n",
    "        return self\n",
    "\n",
    "    def filter_edges(self, condition):\n",
    "        self.edges = self.edges.filter(condition)\n",
    "        return self\n",
    "\n",
    "    def update_node(self, node_id: str, update_dict: dict):\n",
    "        self.base.update_node(node_id, update_dict)\n",
    "        return self\n",
    "\n",
    "    def update_edge(self, source: str, target: str, update_dict: dict):\n",
    "        condition = (self.edges[\"source\"] == source) & (self.edges[\"target\"] == target)\n",
    "        for key, value in update_dict.items():\n",
    "            self.edges = self.edges.with_column(key, \n",
    "                daft.where(condition, daft.lit(value), self.edges[key]))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and populate a document\n",
    "doc = (Document(\"doc1\")\n",
    "    .add_text(\"1\", \"This is a document\")\n",
    "    .add_image(\"2\", \"An image in the document\", \"http://example.com/image.jpg\")\n",
    "    .add_audio(\"3\", \"An audio clip\", \"http://example.com/audio.mp3\", 120.5)\n",
    "    .filter_nodes(col(\"type\") != \"audio\"))\n",
    "\n",
    "# Create and populate a graph\n",
    "graph = (Graph(\"graph1\")\n",
    "    .add_node({\"id\": \"1\", \"content\": \"Hello, world!\", \"type\": \"text\"})\n",
    "    .add_node({\"id\": \"2\", \"content\": \"A beautiful landscape\", \"type\": \"image\", \"url\": \"http://example.com/image.jpg\"})\n",
    "    .add_edge({\"source\": \"1\", \"target\": \"2\", \"relation\": \"describes\"})\n",
    "    .update_node(\"1\", {\"content\": \"Updated content\"})\n",
    "    .filter_edges(col(\"relation\") == \"describes\"))\n",
    "\n",
    "# Get nodes and edges\n",
    "doc_nodes = doc.get_nodes()\n",
    "graph_nodes = graph.get_nodes()\n",
    "graph_edges = graph.get_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Task Network,:\n",
    "class HTN():\n",
    "    def __init__(self, index):\n",
    "        self.graph = Graph(index)\n",
    "\n",
    "    def add_node(self, node_data: dict):\n",
    "        new_node = DataFrame.from_pydict(node_data)\n",
    "        self.nodes = self.nodes.concat(new_node)\n",
    "        return self\n",
    "\n",
    "    def add_edge(self, edge_data: dict):\n",
    "        new_edge = DataFrame.from_pydict(edge_data)\n",
    "        self.edges = self.edges.concat(new_edge)\n",
    "        return self\n",
    "\n",
    "    def get_nodes(self):\n",
    "        return self.nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
